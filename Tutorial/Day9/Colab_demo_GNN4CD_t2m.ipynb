{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fe26aed0-0e4c-4505-a1fe-2179b9b32d90",
      "metadata": {
        "id": "fe26aed0-0e4c-4505-a1fe-2179b9b32d90"
      },
      "source": [
        "# GNN4CD: temperature downscaling\n",
        "\n",
        "In this tutorial we will use the GNN4CD model (Blasone et al.) to downscale SPHERA t2m starting from ERA5 atmospheric variables q, u, v, z.\n",
        "\n",
        "Since the training requires considerable HPC resources, we use an already trained model to perform inference.\n",
        "\n",
        "To run the notebook you can use the environment GNNenv, running the following command\n",
        "`conda activate /leonardo/home/userexternal/vblasone/.conda/envs/GNNenv`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIx7bDDLY5cB",
        "outputId": "34d0359d-7dfa-444e-90a1-bf4aff75927d"
      },
      "id": "fIx7bDDLY5cB",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "282419ce-2eee-4bdb-86c8-c929aa588566",
      "metadata": {
        "id": "282419ce-2eee-4bdb-86c8-c929aa588566"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41d1twWUa_T7",
        "outputId": "cdd32044-7ff3-4096-d235-229cfdd1ea29"
      },
      "id": "41d1twWUa_T7",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏬ Downloading https://github.com/jaimergp/miniforge/releases/download/24.11.2-1_colab/Miniforge3-colab-24.11.2-1_colab-Linux-x86_64.sh...\n",
            "📦 Installing...\n",
            "📌 Adjusting configuration...\n",
            "🩹 Patching environment...\n",
            "⏲ Done in 0:00:09\n",
            "🔁 Restarting kernel...\n",
            "\n",
            "CondaValueError: Invalid environment name: '/leonardo/pub/userexternal/sdigioia/sdigioia/env/RLenv'\n",
            "Characters not allowed: {'/', '#', ':', ' '}\n",
            "If you are specifying a path to an environment, the `-p`\n",
            "flag should be used instead.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda env create python==3.10 -f /content/environment.yml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "htYbBojKcKvW",
        "outputId": "9ca38ba2-5339-4f5e-f3ff-d6eb7a3ea3c1"
      },
      "id": "htYbBojKcKvW",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/argparse.py:1983: FutureWarning: `remote_definition` is deprecated and will be removed in 25.9. Use `conda env create --file=URL` instead.\n",
            "  action(self, namespace, argument_values, option_string)\n",
            "Channels:\n",
            " - conda-forge\n",
            " - defaults\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Solving environment: \\ \b\b| \b\b/ \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "    current version: 24.11.2\n",
            "    latest version: 25.7.0\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c conda-forge conda\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "\n",
            "Preparing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Verifying transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Executing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ By downloading and using the CUDA Toolkit conda packages, you accept the terms and conditions of the CUDA End User License Agreement (EULA): https://docs.nvidia.com/cuda/eula/index.html\n",
            "\n",
            "\b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b-  \n",
            "For Linux 64, Open MPI is built with CUDA awareness but this support is disabled by default.\n",
            "To enable it, please set the environment variable OMPI_MCA_opal_cuda_support=true before\n",
            "launching your MPI processes. Equivalently, you can set the MCA parameter in the command line:\n",
            "mpiexec --mca opal_cuda_support 1 ...\n",
            " \n",
            "In addition, the UCX support is also built but disabled by default.\n",
            "To enable it, first install UCX (conda install -c conda-forge ucx). Then, set the environment\n",
            "variables OMPI_MCA_pml=\"ucx\" OMPI_MCA_osc=\"ucx\" before launching your MPI processes.\n",
            "Equivalently, you can set the MCA parameters in the command line:\n",
            "mpiexec --mca pml ucx --mca osc ucx ...\n",
            "Note that you might also need to set UCX_MEMTYPE_CACHE=n for CUDA awareness via UCX.\n",
            "Please consult UCX's documentation for detail.\n",
            " \n",
            "\n",
            "\b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Installing pip dependencies: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- Ran pip subprocess with arguments:\n",
            "['/usr/local/envs/GNNenv/bin/python', '-m', 'pip', 'install', '-U', '-r', '/content/condaenv.chicm1ke.requirements.txt', '--exists-action=b']\n",
            "Pip subprocess output:\n",
            "Collecting accelerate==0.22.0 (from -r /content/condaenv.chicm1ke.requirements.txt (line 1))\n",
            "  Obtaining dependency information for accelerate==0.22.0 from https://files.pythonhosted.org/packages/4d/a7/05c67003d659a0035f2b3a8cf389c1d9645865aee84a73ce99ddab16682f/accelerate-0.22.0-py3-none-any.whl.metadata\n",
            "  Using cached accelerate-0.22.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting aiohappyeyeballs==2.6.1 (from -r /content/condaenv.chicm1ke.requirements.txt (line 2))\n",
            "  Obtaining dependency information for aiohappyeyeballs==2.6.1 from https://files.pythonhosted.org/packages/0f/15/5bf3b99495fb160b63f95972b81750f18f7f4e02ad051373b669d17d44f2/aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata\n",
            "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiohttp==3.11.14 (from -r /content/condaenv.chicm1ke.requirements.txt (line 3))\n",
            "  Obtaining dependency information for aiohttp==3.11.14 from https://files.pythonhosted.org/packages/c7/21/f3230a9f78bb4a4c4462040bf8425ebb673e3773dd17fd9d06d1af43a955/aiohttp-3.11.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Using cached aiohttp-3.11.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting aiosignal==1.3.2 (from -r /content/condaenv.chicm1ke.requirements.txt (line 4))\n",
            "  Obtaining dependency information for aiosignal==1.3.2 from https://files.pythonhosted.org/packages/ec/6a/bc7e17a3e87a2985d3e8f4da4cd0f481060eb78fb08596c42be62c90a4d9/aiosignal-1.3.2-py2.py3-none-any.whl.metadata\n",
            "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting anyio==3.7.1 (from -r /content/condaenv.chicm1ke.requirements.txt (line 5))\n",
            "  Obtaining dependency information for anyio==3.7.1 from https://files.pythonhosted.org/packages/19/24/44299477fe7dcc9cb58d0a57d5a7588d6af2ff403fdd2d47a246c91a3246/anyio-3.7.1-py3-none-any.whl.metadata\n",
            "  Using cached anyio-3.7.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting appdirs==1.4.4 (from -r /content/condaenv.chicm1ke.requirements.txt (line 6))\n",
            "  Obtaining dependency information for appdirs==1.4.4 from https://files.pythonhosted.org/packages/3b/00/2344469e2084fb287c2e0b57b72910309874c3245463acd6cf5e3db69324/appdirs-1.4.4-py2.py3-none-any.whl.metadata\n",
            "  Using cached appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting argon2-cffi==23.1.0 (from -r /content/condaenv.chicm1ke.requirements.txt (line 7))\n",
            "  Obtaining dependency information for argon2-cffi==23.1.0 from https://files.pythonhosted.org/packages/a4/6a/e8a041599e78b6b3752da48000b14c8d1e8a04ded09c88c714ba047f34f5/argon2_cffi-23.1.0-py3-none-any.whl.metadata\n",
            "  Using cached argon2_cffi-23.1.0-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting argon2-cffi-bindings==21.2.0 (from -r /content/condaenv.chicm1ke.requirements.txt (line 8))\n",
            "  Obtaining dependency information for argon2-cffi-bindings==21.2.0 from https://files.pythonhosted.org/packages/ec/f7/378254e6dd7ae6f31fe40c8649eea7d4832a42243acaf0f1fff9083b2bed/argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Using cached argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting arrow==1.2.3 (from -r /content/condaenv.chicm1ke.requirements.txt (line 9))\n",
            "  Obtaining dependency information for arrow==1.2.3 from https://files.pythonhosted.org/packages/67/67/4bca5a595e2f89bff271724ddb1098e6c9e16f7f3d018d120255e3c30313/arrow-1.2.3-py3-none-any.whl.metadata\n",
            "  Using cached arrow-1.2.3-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting async-lru==2.0.4 (from -r /content/condaenv.chicm1ke.requirements.txt (line 10))\n",
            "  Obtaining dependency information for async-lru==2.0.4 from https://files.pythonhosted.org/packages/fa/9f/3c3503693386c4b0f245eaf5ca6198e3b28879ca0a40bde6b0e319793453/async_lru-2.0.4-py3-none-any.whl.metadata\n",
            "  Using cached async_lru-2.0.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting async-timeout==5.0.1 (from -r /content/condaenv.chicm1ke.requirements.txt (line 11))\n",
            "  Obtaining dependency information for async-timeout==5.0.1 from https://files.pythonhosted.org/packages/fe/ba/e2081de779ca30d473f21f5b30e0e737c438205440784c7dfc81efc2b029/async_timeout-5.0.1-py3-none-any.whl.metadata\n",
            "  Using cached async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting attrs==23.1.0 (from -r /content/condaenv.chicm1ke.requirements.txt (line 12))\n",
            "  Obtaining dependency information for attrs==23.1.0 from https://files.pythonhosted.org/packages/f0/eb/fcb708c7bf5056045e9e98f62b93bd7467eb718b0202e7698eb11d66416c/attrs-23.1.0-py3-none-any.whl.metadata\n",
            "  Using cached attrs-23.1.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting babel==2.12.1 (from -r /content/condaenv.chicm1ke.requirements.txt (line 13))\n",
            "  Obtaining dependency information for babel==2.12.1 from https://files.pythonhosted.org/packages/df/c4/1088865e0246d7ecf56d819a233ab2b72f7d6ab043965ef327d0731b5434/Babel-2.12.1-py3-none-any.whl.metadata\n",
            "  Using cached Babel-2.12.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting beautifulsoup4==4.12.2 (from -r /content/condaenv.chicm1ke.requirements.txt (line 14))\n",
            "  Obtaining dependency information for beautifulsoup4==4.12.2 from https://files.pythonhosted.org/packages/57/f4/a69c20ee4f660081a7dedb1ac57f29be9378e04edfcb90c526b923d4bebc/beautifulsoup4-4.12.2-py3-none-any.whl.metadata\n",
            "  Using cached beautifulsoup4-4.12.2-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting bleach==6.0.0 (from -r /content/condaenv.chicm1ke.requirements.txt (line 15))\n",
            "  Obtaining dependency information for bleach==6.0.0 from https://files.pythonhosted.org/packages/ac/e2/dfcab68c9b2e7800c8f06b85c76e5f978d05b195a958daa9b1dda54a1db6/bleach-6.0.0-py3-none-any.whl.metadata\n",
            "  Using cached bleach-6.0.0-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting bokeh==3.6.3 (from -r /content/condaenv.chicm1ke.requirements.txt (line 16))\n",
            "  Obtaining dependency information for bokeh==3.6.3 from https://files.pythonhosted.org/packages/c5/15/be88ca93d191f07df76cce217b3b44d5ed3038fa58dd33b4fcb12ea8fe5e/bokeh-3.6.3-py3-none-any.whl.metadata\n",
            "  Using cached bokeh-3.6.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting cachetools==5.5.2 (from -r /content/condaenv.chicm1ke.requirements.txt (line 17))\n",
            "  Obtaining dependency information for cachetools==5.5.2 from https://files.pythonhosted.org/packages/72/76/20fa66124dbe6be5cafeb312ece67de6b61dd91a0247d1ea13db4ebb33c2/cachetools-5.5.2-py3-none-any.whl.metadata\n",
            "  Using cached cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting cffi==1.15.1 (from -r /content/condaenv.chicm1ke.requirements.txt (line 18))\n",
            "  Obtaining dependency information for cffi==1.15.1 from https://files.pythonhosted.org/packages/88/89/c34caf63029fb7628ec2ebd5c88ae0c9bd17db98c812e4065a4d020ca41f/cffi-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Using cached cffi-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting cftime==1.6.2 (from -r /content/condaenv.chicm1ke.requirements.txt (line 19))\n",
            "  Obtaining dependency information for cftime==1.6.2 from https://files.pythonhosted.org/packages/e1/17/d8042d82f44c08549b535bf2e7d1e87aa1863df5ed6cf1cf773eb2dfdf67/cftime-1.6.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Using cached cftime-1.6.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
            "Collecting click==8.1.7 (from -r /content/condaenv.chicm1ke.requirements.txt (line 20))\n",
            "  Obtaining dependency information for click==8.1.7 from https://files.pythonhosted.org/packages/00/2e/d53fa4befbf2cfa713304affc7ca780ce4fc1fd8710527771b58311a3229/click-8.1.7-py3-none-any.whl.metadata\n",
            "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting cloudpickle==3.1.1 (from -r /content/condaenv.chicm1ke.requirements.txt (line 21))\n",
            "  Obtaining dependency information for cloudpickle==3.1.1 from https://files.pythonhosted.org/packages/7e/e8/64c37fadfc2816a7701fa8a6ed8d87327c7d54eacfbfb6edab14a2f2be75/cloudpickle-3.1.1-py3-none-any.whl.metadata\n",
            "  Using cached cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting cmake==3.25.0 (from -r /content/condaenv.chicm1ke.requirements.txt (line 22))\n",
            "  Obtaining dependency information for cmake==3.25.0 from https://files.pythonhosted.org/packages/43/fd/298b2055e718cb1eca005b5e5e739564cc68b12becd35fb32345e9b18faf/cmake-3.25.0-py2.py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Using cached cmake-3.25.0-py2.py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting colorcet==3.1.0 (from -r /content/condaenv.chicm1ke.requirements.txt (line 23))\n",
            "  Obtaining dependency information for colorcet==3.1.0 from https://files.pythonhosted.org/packages/c6/c6/9963d588cc3d75d766c819e0377a168ef83cf3316a92769971527a1ad1de/colorcet-3.1.0-py3-none-any.whl.metadata\n",
            "  Using cached colorcet-3.1.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting comm==0.1.4 (from -r /content/condaenv.chicm1ke.requirements.txt (line 24))\n",
            "  Obtaining dependency information for comm==0.1.4 from https://files.pythonhosted.org/packages/fe/47/0133ac1b7dc476ed77710715e98077119b3d9bae56b13f6f9055e7da1c53/comm-0.1.4-py3-none-any.whl.metadata\n",
            "  Using cached comm-0.1.4-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting contourpy==1.3.1 (from -r /content/condaenv.chicm1ke.requirements.txt (line 25))\n",
            "  Obtaining dependency information for contourpy==1.3.1 from https://files.pythonhosted.org/packages/a9/57/86c500d63b3e26e5b73a28b8291a67c5608d4aa87ebd17bd15bb33c178bc/contourpy-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Using cached contourpy-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
            "Collecting cubinlinker-cu11==0.3.0.post2 (from -r /content/condaenv.chicm1ke.requirements.txt (line 26))\n",
            "  Using cached cubinlinker_cu11-0.3.0.post2.tar.gz (513 bytes)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Collecting cuda-bindings==11.8.6 (from -r /content/condaenv.chicm1ke.requirements.txt (line 27))\n",
            "  Obtaining dependency information for cuda-bindings==11.8.6 from https://files.pythonhosted.org/packages/75/76/bfa4596a5932e6d5e8c990c347b803a650c01d1975d250a468301ff8d205/cuda_bindings-11.8.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Using cached cuda_bindings-11.8.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting cuda-python==11.8.6 (from -r /content/condaenv.chicm1ke.requirements.txt (line 28))\n",
            "  Obtaining dependency information for cuda-python==11.8.6 from https://files.pythonhosted.org/packages/b8/0c/f87a4609c1a3182b95e3f13b13d49b94faf2b63124ef5c7e30377adc12c1/cuda_python-11.8.6-py3-none-any.whl.metadata\n",
            "  Using cached cuda_python-11.8.6-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting cudf-cu11==25.2.2 (from -r /content/condaenv.chicm1ke.requirements.txt (line 29))\n",
            "  Using cached cudf_cu11-25.2.2.tar.gz (2.7 kB)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Collecting cugraph-cu11==25.2.0 (from -r /content/condaenv.chicm1ke.requirements.txt (line 30))\n",
            "  Using cached cugraph_cu11-25.2.0.tar.gz (4.2 kB)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Collecting cuml-cu11==25.2.1 (from -r /content/condaenv.chicm1ke.requirements.txt (line 31))\n",
            "  Using cached cuml_cu11-25.2.1.tar.gz (2.5 kB)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Collecting cupy-cuda11x==13.4.0 (from -r /content/condaenv.chicm1ke.requirements.txt (line 32))\n",
            "  Obtaining dependency information for cupy-cuda11x==13.4.0 from https://files.pythonhosted.org/packages/38/8f/eac59e60ff35c9ffadb097564073bd778a078ccc4d4947786da352a22453/cupy_cuda11x-13.4.0-cp310-cp310-manylinux2014_x86_64.whl.metadata\n",
            "  Using cached cupy_cuda11x-13.4.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "Collecting cuvs-cu11==25.2.1 (from -r /content/condaenv.chicm1ke.requirements.txt (line 33))\n",
            "  Using cached cuvs_cu11-25.2.1.tar.gz (1.0 kB)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Collecting cycler==0.11.0 (from -r /content/condaenv.chicm1ke.requirements.txt (line 34))\n",
            "  Obtaining dependency information for cycler==0.11.0 from https://files.pythonhosted.org/packages/5c/f9/695d6bedebd747e5eb0fe8fad57b72fdf25411273a39791cde838d5a8f51/cycler-0.11.0-py3-none-any.whl.metadata\n",
            "  Using cached cycler-0.11.0-py3-none-any.whl.metadata (785 bytes)\n",
            "Collecting dask==2024.12.1 (from -r /content/condaenv.chicm1ke.requirements.txt (line 35))\n",
            "  Obtaining dependency information for dask==2024.12.1 from https://files.pythonhosted.org/packages/6d/5a/cdc78a77bb1c7290fd1ccfe6001437f99a2af63e28343299abd09336236e/dask-2024.12.1-py3-none-any.whl.metadata\n",
            "  Using cached dask-2024.12.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting dask-cuda==25.2.0 (from -r /content/condaenv.chicm1ke.requirements.txt (line 36))\n",
            "  Obtaining dependency information for dask-cuda==25.2.0 from https://files.pythonhosted.org/packages/14/72/40f0f160ef058cc8c98582744b4053cc4f05d1330dfc2904873bdccd205c/dask_cuda-25.2.0-py3-none-any.whl.metadata\n",
            "  Using cached dask_cuda-25.2.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting dask-cudf-cu11==25.2.2 (from -r /content/condaenv.chicm1ke.requirements.txt (line 37))\n",
            "  Using cached dask_cudf_cu11-25.2.2.tar.gz (2.4 kB)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Collecting dask-expr==1.1.21 (from -r /content/condaenv.chicm1ke.requirements.txt (line 38))\n",
            "  Obtaining dependency information for dask-expr==1.1.21 from https://files.pythonhosted.org/packages/a9/99/60c73ccb5a272ff396bc766bfa3c9caa71484424983f0334070263a16581/dask_expr-1.1.21-py3-none-any.whl.metadata\n",
            "  Using cached dask_expr-1.1.21-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting datashader==0.17.0 (from -r /content/condaenv.chicm1ke.requirements.txt (line 39))\n",
            "  Obtaining dependency information for datashader==0.17.0 from https://files.pythonhosted.org/packages/dc/52/755bbab06c4d10f693abb724e82271ccf8adc98e9305a5c559867ee40c98/datashader-0.17.0-py3-none-any.whl.metadata\n",
            "  Using cached datashader-0.17.0-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting debugpy==1.6.7.post1 (from -r /content/condaenv.chicm1ke.requirements.txt (line 40))\n",
            "  Obtaining dependency information for debugpy==1.6.7.post1 from https://files.pythonhosted.org/packages/33/a4/0dffe40fc4de1850e8e430f24fcd00570c3072086aea3c2e79bb18ba3e1a/debugpy-1.6.7.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Using cached debugpy-1.6.7.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting defusedxml==0.7.1 (from -r /content/condaenv.chicm1ke.requirements.txt (line 41))\n",
            "  Obtaining dependency information for defusedxml==0.7.1 from https://files.pythonhosted.org/packages/07/6c/aa3f2f849e01cb6a001cd8554a88d4c77c5c1a31c95bdf1cf9301e6d9ef4/defusedxml-0.7.1-py2.py3-none-any.whl.metadata\n",
            "  Using cached defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
            "Collecting distributed==2024.12.1 (from -r /content/condaenv.chicm1ke.requirements.txt (line 42))\n",
            "  Obtaining dependency information for distributed==2024.12.1 from https://files.pythonhosted.org/packages/e8/90/82171cc7fe1c6d10bac57587c7ac012be80412ad06ef8c4952c5f067f869/distributed-2024.12.1-py3-none-any.whl.metadata\n",
            "  Using cached distributed-2024.12.1-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting distributed-ucxx-cu11==0.42.0 (from -r /content/condaenv.chicm1ke.requirements.txt (line 43))\n",
            "  Using cached distributed_ucxx_cu11-0.42.0.tar.gz (999 bytes)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Collecting docker-pycreds==0.4.0 (from -r /content/condaenv.chicm1ke.requirements.txt (line 44))\n",
            "  Obtaining dependency information for docker-pycreds==0.4.0 from https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata\n",
            "  Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting exceptiongroup==1.1.3 (from -r /content/condaenv.chicm1ke.requirements.txt (line 45))\n",
            "  Obtaining dependency information for exceptiongroup==1.1.3 from https://files.pythonhosted.org/packages/ad/83/b71e58666f156a39fb29417e4c8ca4bc7400c0dd4ed9e8842ab54dc8c344/exceptiongroup-1.1.3-py3-none-any.whl.metadata\n",
            "  Using cached exceptiongroup-1.1.3-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting fastjsonschema==2.18.0 (from -r /content/condaenv.chicm1ke.requirements.txt (line 46))\n",
            "  Obtaining dependency information for fastjsonschema==2.18.0 from https://files.pythonhosted.org/packages/9d/93/a3ca3cdeb84065d7d8f8df4cb09ab44405f109183c1d2b915ec17574e6b1/fastjsonschema-2.18.0-py3-none-any.whl.metadata\n",
            "  Using cached fastjsonschema-2.18.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting filelock==3.9.0 (from -r /content/condaenv.chicm1ke.requirements.txt (line 47))\n",
            "  Obtaining dependency information for filelock==3.9.0 from https://files.pythonhosted.org/packages/14/4c/b201d0292ca4e0950f0741212935eac9996f69cd66b92a3587e594999163/filelock-3.9.0-py3-none-any.whl.metadata\n",
            "  Using cached filelock-3.9.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting fonttools==4.42.1 (from -r /content/condaenv.chicm1ke.requirements.txt (line 48))\n",
            "  Obtaining dependency information for fonttools==4.42.1 from https://files.pythonhosted.org/packages/2b/e8/61b8525acf26ec222518bdff127ae502bfa3408981fb5e5493f2b037d7fb/fonttools-4.42.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Using cached fonttools-4.42.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (150 kB)\n",
            "Collecting fqdn==1.5.1 (from -r /content/condaenv.chicm1ke.requirements.txt (line 49))\n",
            "  Obtaining dependency information for fqdn==1.5.1 from https://files.pythonhosted.org/packages/cf/58/8acf1b3e91c58313ce5cb67df61001fc9dcd21be4fadb76c1a2d540e09ed/fqdn-1.5.1-py3-none-any.whl.metadata\n",
            "  Using cached fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting frozenlist==1.5.0 (from -r /content/condaenv.chicm1ke.requirements.txt (line 50))\n",
            "  Obtaining dependency information for frozenlist==1.5.0 from https://files.pythonhosted.org/packages/ee/59/928322800306f6529d1852323014ee9008551e9bb027cc38d276cbc0b0e7/frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Using cached frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting fsspec==2025.3.0 (from -r /content/condaenv.chicm1ke.requirements.txt (line 51))\n",
            "  Obtaining dependency information for fsspec==2025.3.0 from https://files.pythonhosted.org/packages/56/53/eb690efa8513166adef3e0669afd31e95ffde69fb3c52ec2ac7223ed6018/fsspec-2025.3.0-py3-none-any.whl.metadata\n",
            "  Using cached fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting geopandas==1.0.1 (from -r /content/condaenv.chicm1ke.requirements.txt (line 52))\n",
            "  Obtaining dependency information for geopandas==1.0.1 from https://files.pythonhosted.org/packages/c4/64/7d344cfcef5efddf9cf32f59af7f855828e9d74b5f862eddf5bfd9f25323/geopandas-1.0.1-py3-none-any.whl.metadata\n",
            "  Using cached geopandas-1.0.1-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting gitdb==4.0.10 (from -r /content/condaenv.chicm1ke.requirements.txt (line 53))\n",
            "  Obtaining dependency information for gitdb==4.0.10 from https://files.pythonhosted.org/packages/21/a6/35f83efec687615c711fe0a09b67e58f6d1254db27b1013119de46f450bd/gitdb-4.0.10-py3-none-any.whl.metadata\n",
            "  Using cached gitdb-4.0.10-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting gitpython==3.1.32 (from -r /content/condaenv.chicm1ke.requirements.txt (line 54))\n",
            "  Obtaining dependency information for gitpython==3.1.32 from https://files.pythonhosted.org/packages/67/50/742c2fb60989b76ccf7302c7b1d9e26505d7054c24f08cc7ec187faaaea7/GitPython-3.1.32-py3-none-any.whl.metadata\n",
            "  Using cached GitPython-3.1.32-py3-none-any.whl.metadata (10.0 kB)\n",
            "Collecting h5netcdf==1.2.0 (from -r /content/condaenv.chicm1ke.requirements.txt (line 55))\n",
            "  Obtaining dependency information for h5netcdf==1.2.0 from https://files.pythonhosted.org/packages/d1/11/8116d6f209c8588ceb1382fddb8820fc720330373d9bd1a09434d684dbde/h5netcdf-1.2.0-py3-none-any.whl.metadata\n",
            "  Using cached h5netcdf-1.2.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting h5py==3.9.0 (from -r /content/condaenv.chicm1ke.requirements.txt (line 56))\n",
            "  Obtaining dependency information for h5py==3.9.0 from https://files.pythonhosted.org/packages/0d/7a/e55589e4093cca1934db5e99644c1c2424a9b3aac104b7f6176605a5eeb7/h5py-3.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Using cached h5py-3.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Collecting holoviews==1.20.2 (from -r /content/condaenv.chicm1ke.requirements.txt (line 57))\n",
            "  Obtaining dependency information for holoviews==1.20.2 from https://files.pythonhosted.org/packages/df/67/066a1d984fa259ad7300084a70789579e104afd75fc58a1d44cda9c365d5/holoviews-1.20.2-py3-none-any.whl.metadata\n",
            "  Using cached holoviews-1.20.2-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting imageio==2.37.0 (from -r /content/condaenv.chicm1ke.requirements.txt (line 58))\n",
            "  Obtaining dependency information for imageio==2.37.0 from https://files.pythonhosted.org/packages/cb/bd/b394387b598ed84d8d0fa90611a90bee0adc2021820ad5729f7ced74a8e2/imageio-2.37.0-py3-none-any.whl.metadata\n",
            "  Using cached imageio-2.37.0-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting importlib-metadata==8.6.1 (from -r /content/condaenv.chicm1ke.requirements.txt (line 59))\n",
            "  Obtaining dependency information for importlib-metadata==8.6.1 from https://files.pythonhosted.org/packages/79/9d/0fb148dc4d6fa4a7dd1d8378168d9b4cd8d4560a6fbf6f0121c5fc34eb68/importlib_metadata-8.6.1-py3-none-any.whl.metadata\n",
            "  Using cached importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting ipykernel==6.25.1 (from -r /content/condaenv.chicm1ke.requirements.txt (line 60))\n",
            "  Obtaining dependency information for ipykernel==6.25.1 from https://files.pythonhosted.org/packages/ca/ca/1089ddd8dd3ba03ea593bf20cdc2f7fe02526dcd7d966b7da47aa105e65b/ipykernel-6.25.1-py3-none-any.whl.metadata\n",
            "  Using cached ipykernel-6.25.1-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting isoduration==20.11.0 (from -r /content/condaenv.chicm1ke.requirements.txt (line 61))\n",
            "  Obtaining dependency information for isoduration==20.11.0 from https://files.pythonhosted.org/packages/7b/55/e5326141505c5d5e34c5e0935d2908a74e4561eca44108fbfb9c13d2911a/isoduration-20.11.0-py3-none-any.whl.metadata\n",
            "  Using cached isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jinja2==3.1.2 (from -r /content/condaenv.chicm1ke.requirements.txt (line 62))\n",
            "  Obtaining dependency information for jinja2==3.1.2 from https://files.pythonhosted.org/packages/bc/c3/f068337a370801f372f2f8f6bad74a5c140f6fda3d9de154052708dd3c65/Jinja2-3.1.2-py3-none-any.whl.metadata\n",
            "  Using cached Jinja2-3.1.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting json5==0.9.14 (from -r /content/condaenv.chicm1ke.requirements.txt (line 63))\n",
            "  Obtaining dependency information for json5==0.9.14 from https://files.pythonhosted.org/packages/70/ba/fa37123a86ae8287d6678535a944f9c3377d8165e536310ed6f6cb0f0c0e/json5-0.9.14-py2.py3-none-any.whl.metadata\n",
            "  Using cached json5-0.9.14-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting jsonpointer==2.4 (from -r /content/condaenv.chicm1ke.requirements.txt (line 64))\n",
            "  Obtaining dependency information for jsonpointer==2.4 from https://files.pythonhosted.org/packages/12/f6/0232cc0c617e195f06f810534d00b74d2f348fe71b2118009ad8ad31f878/jsonpointer-2.4-py2.py3-none-any.whl.metadata\n",
            "  Using cached jsonpointer-2.4-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting jsonschema==4.19.0 (from -r /content/condaenv.chicm1ke.requirements.txt (line 65))\n",
            "  Obtaining dependency information for jsonschema==4.19.0 from https://files.pythonhosted.org/packages/2b/ff/af59fd34bc4d7ac3e6e0cd1f3c10317d329b6c1aee179e8b24ad9a79fbac/jsonschema-4.19.0-py3-none-any.whl.metadata\n",
            "  Using cached jsonschema-4.19.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting jsonschema-specifications==2023.7.1 (from -r /content/condaenv.chicm1ke.requirements.txt (line 66))\n",
            "  Obtaining dependency information for jsonschema-specifications==2023.7.1 from https://files.pythonhosted.org/packages/1c/24/83349ac2189cc2435e84da3f69ba3c97314d3c0622628e55171c6798ed80/jsonschema_specifications-2023.7.1-py3-none-any.whl.metadata\n",
            "  Using cached jsonschema_specifications-2023.7.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting jupyter-client==8.3.0 (from -r /content/condaenv.chicm1ke.requirements.txt (line 67))\n",
            "  Obtaining dependency information for jupyter-client==8.3.0 from https://files.pythonhosted.org/packages/29/24/0491f7837cedf39ae0f96d9b3e4db2fae31cc4dd5eac00a98ab0db996c9b/jupyter_client-8.3.0-py3-none-any.whl.metadata\n",
            "  Using cached jupyter_client-8.3.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting jupyter-core==5.3.1 (from -r /content/condaenv.chicm1ke.requirements.txt (line 68))\n",
            "  Obtaining dependency information for jupyter-core==5.3.1 from https://files.pythonhosted.org/packages/8c/e0/3f9061c5e99a03612510f892647b15a91f910c5275b7b77c6c72edae1494/jupyter_core-5.3.1-py3-none-any.whl.metadata\n",
            "  Using cached jupyter_core-5.3.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting jupyter-events==0.7.0 (from -r /content/condaenv.chicm1ke.requirements.txt (line 69))\n",
            "  Obtaining dependency information for jupyter-events==0.7.0 from https://files.pythonhosted.org/packages/15/0d/3c67f6c432d8085a3cee250e1e235f27b764be90cc2d16fdcc0b1cee9572/jupyter_events-0.7.0-py3-none-any.whl.metadata\n",
            "  Using cached jupyter_events-0.7.0-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting jupyter-lsp==2.2.0 (from -r /content/condaenv.chicm1ke.requirements.txt (line 70))\n",
            "  Obtaining dependency information for jupyter-lsp==2.2.0 from https://files.pythonhosted.org/packages/8f/b6/a1571e48550855a79898f851f57e5858b00eb36b09ea3b1a8bb65c53a290/jupyter_lsp-2.2.0-py3-none-any.whl.metadata\n",
            "  Using cached jupyter_lsp-2.2.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting jupyter-server==2.7.2 (from -r /content/condaenv.chicm1ke.requirements.txt (line 71))\n",
            "  Obtaining dependency information for jupyter-server==2.7.2 from https://files.pythonhosted.org/packages/28/d9/4bf2ab8410cdc37f54aadb6cae497b9bc8ae16720d97b762b9bfb7834022/jupyter_server-2.7.2-py3-none-any.whl.metadata\n",
            "  Using cached jupyter_server-2.7.2-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting jupyter-server-proxy==4.4.0 (from -r /content/condaenv.chicm1ke.requirements.txt (line 72))\n",
            "  Obtaining dependency information for jupyter-server-proxy==4.4.0 from https://files.pythonhosted.org/packages/fd/c6/e4a1d9fdd22d40962befd82780a98b20b67ef9cafe87246e4955f44b8f09/jupyter_server_proxy-4.4.0-py3-none-any.whl.metadata\n",
            "  Using cached jupyter_server_proxy-4.4.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting jupyter-server-terminals==0.4.4 (from -r /content/condaenv.chicm1ke.requirements.txt (line 73))\n",
            "  Obtaining dependency information for jupyter-server-terminals==0.4.4 from https://files.pythonhosted.org/packages/ea/7f/36db12bdb90f5237766dcbf59892198daab7260acbcf03fc75e2a2a82672/jupyter_server_terminals-0.4.4-py3-none-any.whl.metadata\n",
            "  Using cached jupyter_server_terminals-0.4.4-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jupyterlab==4.0.5 (from -r /content/condaenv.chicm1ke.requirements.txt (line 74))\n",
            "  Obtaining dependency information for jupyterlab==4.0.5 from https://files.pythonhosted.org/packages/71/a3/38b9d6492a393dcfdae9e82021655432a9fd6e8f4c03c30a7b55036c0d70/jupyterlab-4.0.5-py3-none-any.whl.metadata\n",
            "  Using cached jupyterlab-4.0.5-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting jupyterlab-pygments==0.2.2 (from -r /content/condaenv.chicm1ke.requirements.txt (line 75))\n",
            "  Obtaining dependency information for jupyterlab-pygments==0.2.2 from https://files.pythonhosted.org/packages/c0/7e/c3d1df3ae9b41686e664051daedbd70eea2e1d2bd9d9c33e7e1455bc9f96/jupyterlab_pygments-0.2.2-py2.py3-none-any.whl.metadata\n",
            "  Using cached jupyterlab_pygments-0.2.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting jupyterlab-server==2.24.0 (from -r /content/condaenv.chicm1ke.requirements.txt (line 76))\n",
            "  Obtaining dependency information for jupyterlab-server==2.24.0 from https://files.pythonhosted.org/packages/a7/0d/6d4eab0391bd4df1c43f308368d5e177b0fa8ac632267222a23b71317091/jupyterlab_server-2.24.0-py3-none-any.whl.metadata\n",
            "  Using cached jupyterlab_server-2.24.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting kiwisolver==1.4.5 (from -r /content/condaenv.chicm1ke.requirements.txt (line 77))\n",
            "  Obtaining dependency information for kiwisolver==1.4.5 from https://files.pythonhosted.org/packages/6f/40/4ab1fdb57fced80ce5903f04ae1aed7c1d5939dda4fd0c0aa526c12fe28a/kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata\n",
            "  Using cached kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting lazy-loader==0.4 (from -r /content/condaenv.chicm1ke.requirements.txt (line 78))\n",
            "  Obtaining dependency information for lazy-loader==0.4 from https://files.pythonhosted.org/packages/83/60/d497a310bde3f01cb805196ac61b7ad6dc5dcf8dce66634dc34364b20b4f/lazy_loader-0.4-py3-none-any.whl.metadata\n",
            "  Using cached lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting libcudf-cu11==25.2.2 (from -r /content/condaenv.chicm1ke.requirements.txt (line 79))\n",
            "  Using cached libcudf_cu11-25.2.2.tar.gz (2.2 kB)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Collecting libcugraph-cu11==25.2.0 (from -r /content/condaenv.chicm1ke.requirements.txt (line 80))\n",
            "  Using cached libcugraph_cu11-25.2.0.tar.gz (4.0 kB)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Collecting libcuml-cu11==25.2.1 (from -r /content/condaenv.chicm1ke.requirements.txt (line 81))\n",
            "  Using cached libcuml_cu11-25.2.1.tar.gz (4.1 kB)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Collecting libcuspatial-cu11==25.2.0 (from -r /content/condaenv.chicm1ke.requirements.txt (line 82))\n",
            "  Using cached libcuspatial_cu11-25.2.0.tar.gz (3.8 kB)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Collecting libcuvs-cu11==25.2.1 (from -r /content/condaenv.chicm1ke.requirements.txt (line 83))\n",
            "  Using cached libcuvs_cu11-25.2.1.tar.gz (4.9 kB)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Collecting libkvikio-cu11==25.2.1 (from -r /content/condaenv.chicm1ke.requirements.txt (line 84))\n",
            "  Using cached libkvikio_cu11-25.2.1.tar.gz (2.0 kB)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Collecting libraft-cu11==25.2.0 (from -r /content/condaenv.chicm1ke.requirements.txt (line 85))\n",
            "  Using cached libraft_cu11-25.2.0.tar.gz (5.5 kB)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Collecting libucx-cu11==1.18.0 (from -r /content/condaenv.chicm1ke.requirements.txt (line 86))\n",
            "  Obtaining dependency information for libucx-cu11==1.18.0 from https://files.pythonhosted.org/packages/7a/e1/489636e372c208b472b5212f3a47dbb84780bb401017f66c9ce51ff6bc98/libucx_cu11-1.18.0-py3-none-manylinux_2_28_x86_64.whl.metadata\n",
            "  Using cached libucx_cu11-1.18.0-py3-none-manylinux_2_28_x86_64.whl.metadata (2.9 kB)\n",
            "Collecting libucxx-cu11==0.42.0 (from -r /content/condaenv.chicm1ke.requirements.txt (line 87))\n",
            "  Using cached libucxx_cu11-0.42.0.tar.gz (3.0 kB)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Collecting lightning-utilities==0.9.0 (from -r /content/condaenv.chicm1ke.requirements.txt (line 88))\n",
            "  Obtaining dependency information for lightning-utilities==0.9.0 from https://files.pythonhosted.org/packages/46/ee/8641eeb6a062f383b7d6875604e1f3f83bd2c93a0b4dbcabd3150b32de6e/lightning_utilities-0.9.0-py3-none-any.whl.metadata\n",
            "  Using cached lightning_utilities-0.9.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting linkify-it-py==2.0.3 (from -r /content/condaenv.chicm1ke.requirements.txt (line 89))\n",
            "  Obtaining dependency information for linkify-it-py==2.0.3 from https://files.pythonhosted.org/packages/04/1e/b832de447dee8b582cac175871d2f6c3d5077cc56d5575cadba1fd1cccfa/linkify_it_py-2.0.3-py3-none-any.whl.metadata\n",
            "  Using cached linkify_it_py-2.0.3-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting lit==15.0.7 (from -r /content/condaenv.chicm1ke.requirements.txt (line 90))\n",
            "  Using cached lit-15.0.7.tar.gz (132 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting llvmlite==0.43.0 (from -r /content/condaenv.chicm1ke.requirements.txt (line 91))\n",
            "  Obtaining dependency information for llvmlite==0.43.0 from https://files.pythonhosted.org/packages/c6/21/2ffbab5714e72f2483207b4a1de79b2eecd9debbf666ff4e7067bcc5c134/llvmlite-0.43.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Using cached llvmlite-0.43.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting locket==1.0.0 (from -r /content/condaenv.chicm1ke.requirements.txt (line 92))\n",
            "  Obtaining dependency information for locket==1.0.0 from https://files.pythonhosted.org/packages/db/bc/83e112abc66cd466c6b83f99118035867cecd41802f8d044638aa78a106e/locket-1.0.0-py2.py3-none-any.whl.metadata\n",
            "  Using cached locket-1.0.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting markdown==3.7 (from -r /content/condaenv.chicm1ke.requirements.txt (line 93))\n",
            "  Obtaining dependency information for markdown==3.7 from https://files.pythonhosted.org/packages/3f/08/83871f3c50fc983b88547c196d11cf8c3340e37c32d2e9d6152abe2c61f7/Markdown-3.7-py3-none-any.whl.metadata\n",
            "  Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting markdown-it-py==3.0.0 (from -r /content/condaenv.chicm1ke.requirements.txt (line 94))\n",
            "  Obtaining dependency information for markdown-it-py==3.0.0 from https://files.pythonhosted.org/packages/42/d7/1ec15b46af6af88f19b8e5ffea08fa375d433c998b8a7639e76935c14f1f/markdown_it_py-3.0.0-py3-none-any.whl.metadata\n",
            "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting markupsafe==2.1.2 (from -r /content/condaenv.chicm1ke.requirements.txt (line 95))\n",
            "  Obtaining dependency information for markupsafe==2.1.2 from https://files.pythonhosted.org/packages/3d/66/2f636ba803fd6eb4cee7b3106ae02538d1e84a7fb7f4f8775c6528a87d31/MarkupSafe-2.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Using cached MarkupSafe-2.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Collecting matplotlib==3.7.2 (from -r /content/condaenv.chicm1ke.requirements.txt (line 96))\n",
            "  Obtaining dependency information for matplotlib==3.7.2 from https://files.pythonhosted.org/packages/c2/da/a5622266952ab05dc3995d77689cba600e49ea9d6c51d469c077695cb719/matplotlib-3.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Using cached matplotlib-3.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Collecting mdit-py-plugins==0.4.2 (from -r /content/condaenv.chicm1ke.requirements.txt (line 97))\n",
            "  Obtaining dependency information for mdit-py-plugins==0.4.2 from https://files.pythonhosted.org/packages/a7/f7/7782a043553ee469c1ff49cfa1cdace2d6bf99a1f333cf38676b3ddf30da/mdit_py_plugins-0.4.2-py3-none-any.whl.metadata\n",
            "  Using cached mdit_py_plugins-0.4.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting mdurl==0.1.2 (from -r /content/condaenv.chicm1ke.requirements.txt (line 98))\n",
            "  Obtaining dependency information for mdurl==0.1.2 from https://files.pythonhosted.org/packages/b3/38/89ba8ad64ae25be8de66a6d463314cf1eb366222074cfda9ee839c56a4b4/mdurl-0.1.2-py3-none-any.whl.metadata\n",
            "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting mistune==3.0.1 (from -r /content/condaenv.chicm1ke.requirements.txt (line 99))\n",
            "  Obtaining dependency information for mistune==3.0.1 from https://files.pythonhosted.org/packages/cc/c0/ac9587149e37cde62ae338e9db8241ae2fdc79a84bde8c8ba7caea2c22d8/mistune-3.0.1-py3-none-any.whl.metadata\n",
            "  Using cached mistune-3.0.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting mpi4py==3.1.5 (from -r /content/condaenv.chicm1ke.requirements.txt (line 100))\n",
            "  Using cached mpi4py-3.1.5.tar.gz (2.5 MB)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Collecting mpmath==1.2.1 (from -r /content/condaenv.chicm1ke.requirements.txt (line 101))\n",
            "  Obtaining dependency information for mpmath==1.2.1 from https://files.pythonhosted.org/packages/d4/cf/3965bddbb4f1a61c49aacae0e78fd1fe36b5dc36c797b31f30cf07dcbbb7/mpmath-1.2.1-py3-none-any.whl.metadata\n",
            "  Using cached mpmath-1.2.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting msgpack==1.1.0 (from -r /content/condaenv.chicm1ke.requirements.txt (line 102))\n",
            "  Obtaining dependency information for msgpack==1.1.0 from https://files.pythonhosted.org/packages/ff/75/09081792db60470bef19d9c2be89f024d366b1e1973c197bb59e6aabc647/msgpack-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Using cached msgpack-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
            "Collecting multidict==6.2.0 (from -r /content/condaenv.chicm1ke.requirements.txt (line 103))\n",
            "  Obtaining dependency information for multidict==6.2.0 from https://files.pythonhosted.org/packages/c8/84/4b590a121b1009fe79d1ae5875b4aa9339d37d23e368dd3bcf5e36d27452/multidict-6.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Using cached multidict-6.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting multipledispatch==1.0.0 (from -r /content/condaenv.chicm1ke.requirements.txt (line 104))\n",
            "  Obtaining dependency information for multipledispatch==1.0.0 from https://files.pythonhosted.org/packages/51/c0/00c9809d8b9346eb238a6bbd5f83e846a4ce4503da94a4c08cb7284c325b/multipledispatch-1.0.0-py3-none-any.whl.metadata\n",
            "  Using cached multipledispatch-1.0.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting nbclient==0.8.0 (from -r /content/condaenv.chicm1ke.requirements.txt (line 105))\n",
            "  Obtaining dependency information for nbclient==0.8.0 from https://files.pythonhosted.org/packages/ac/5a/d670ca51e6c3d98574b9647599821590efcd811d71f58e9c89fc59a17685/nbclient-0.8.0-py3-none-any.whl.metadata\n",
            "  Using cached nbclient-0.8.0-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting nbconvert==7.7.4 (from -r /content/condaenv.chicm1ke.requirements.txt (line 106))\n",
            "  Obtaining dependency information for nbconvert==7.7.4 from https://files.pythonhosted.org/packages/80/ed/d883918ca3777f744f3373fc63d8af47b47237ca703450a451b3e885264a/nbconvert-7.7.4-py3-none-any.whl.metadata\n",
            "  Using cached nbconvert-7.7.4-py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting nbformat==5.9.2 (from -r /content/condaenv.chicm1ke.requirements.txt (line 107))\n",
            "  Obtaining dependency information for nbformat==5.9.2 from https://files.pythonhosted.org/packages/f4/e7/ef30a90b70eba39e675689b9eaaa92530a71d7435ab8f9cae520814e0caf/nbformat-5.9.2-py3-none-any.whl.metadata\n",
            "  Using cached nbformat-5.9.2-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting nest-asyncio==1.5.7 (from -r /content/condaenv.chicm1ke.requirements.txt (line 108))\n",
            "  Obtaining dependency information for nest-asyncio==1.5.7 from https://files.pythonhosted.org/packages/7e/dd/69a7a6e89bb1fe09f99bde22027154c487b1e8b6769e642d7f56f35696d3/nest_asyncio-1.5.7-py3-none-any.whl.metadata\n",
            "  Using cached nest_asyncio-1.5.7-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting netcdf4==1.6.4 (from -r /content/condaenv.chicm1ke.requirements.txt (line 109))\n",
            "  Obtaining dependency information for netcdf4==1.6.4 from https://files.pythonhosted.org/packages/3d/2c/3d1f7c1d4287dab5bc997fed8e58bad9fc9aa9c39a692bbf1aab6b1feb19/netCDF4-1.6.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Using cached netCDF4-1.6.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting networkx==3.4.2 (from -r /content/condaenv.chicm1ke.requirements.txt (line 110))\n",
            "  Obtaining dependency information for networkx==3.4.2 from https://files.pythonhosted.org/packages/b9/54/dd730b32ea14ea797530a4479b2ed46a6fb250f682a9cfb997e968bf0261/networkx-3.4.2-py3-none-any.whl.metadata\n",
            "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting notebook==7.0.2 (from -r /content/condaenv.chicm1ke.requirements.txt (line 111))\n",
            "  Obtaining dependency information for notebook==7.0.2 from https://files.pythonhosted.org/packages/85/76/51777158391e1784cc5a892ff355fd0a0b0b5189aeffce9baf51f514b9a2/notebook-7.0.2-py3-none-any.whl.metadata\n",
            "  Using cached notebook-7.0.2-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting notebook-shim==0.2.3 (from -r /content/condaenv.chicm1ke.requirements.txt (line 112))\n",
            "  Obtaining dependency information for notebook-shim==0.2.3 from https://files.pythonhosted.org/packages/f4/79/73250372e5bbab63018b41b02d5cc6b395655ec6c1254e477ef7c913aada/notebook_shim-0.2.3-py3-none-any.whl.metadata\n",
            "  Using cached notebook_shim-0.2.3-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting numba==0.60.0 (from -r /content/condaenv.chicm1ke.requirements.txt (line 113))\n",
            "  Obtaining dependency information for numba==0.60.0 from https://files.pythonhosted.org/packages/79/58/cb4ac5b8f7ec64200460aef1fed88258fb872ceef504ab1f989d2ff0f684/numba-0.60.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n",
            "  Using cached numba-0.60.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
            "Collecting numba-cuda==0.2.0 (from -r /content/condaenv.chicm1ke.requirements.txt (line 114))\n",
            "  Obtaining dependency information for numba-cuda==0.2.0 from https://files.pythonhosted.org/packages/c0/88/0c0858a71fec5f34d0ffc3d14528e2c7d6624e48457ab760238a7d633158/numba_cuda-0.2.0-py3-none-any.whl.metadata\n",
            "  Using cached numba_cuda-0.2.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cublas-cu11==11.11.3.6 (from -r /content/condaenv.chicm1ke.requirements.txt (line 115))\n",
            "  Obtaining dependency information for nvidia-cublas-cu11==11.11.3.6 from https://files.pythonhosted.org/packages/ea/2e/9d99c60771d275ecf6c914a612e9a577f740a615bc826bec132368e1d3ae/nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux2014_x86_64.whl.metadata\n",
            "  Using cached nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58 (from -r /content/condaenv.chicm1ke.requirements.txt (line 116))\n",
            "  Obtaining dependency information for nvidia-cufft-cu11==10.9.0.58 from https://files.pythonhosted.org/packages/64/c8/133717b43182ba063803e983e7680a94826a9f4ff5734af0ca315803f1b3/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata\n",
            "  Using cached nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu11==10.3.0.86 (from -r /content/condaenv.chicm1ke.requirements.txt (line 117))\n",
            "  Obtaining dependency information for nvidia-curand-cu11==10.3.0.86 from https://files.pythonhosted.org/packages/58/e5/ce5806afc48a6e4e0dddd25316ac60b6fa94fd1791bdbf4ca17bf52696ea/nvidia_curand_cu11-10.3.0.86-py3-none-manylinux2014_x86_64.whl.metadata\n",
            "  Using cached nvidia_curand_cu11-10.3.0.86-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.1.48 (from -r /content/condaenv.chicm1ke.requirements.txt (line 118))\n",
            "  Obtaining dependency information for nvidia-cusolver-cu11==11.4.1.48 from https://files.pythonhosted.org/packages/52/fe/866e87e6e6a1b0a5fcf8524a058042656702f2057e22bfdb8899a7c38e10/nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux2014_x86_64.whl.metadata\n",
            "  Using cached nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.5.86 (from -r /content/condaenv.chicm1ke.requirements.txt (line 119))\n",
            "  Obtaining dependency information for nvidia-cusparse-cu11==11.7.5.86 from https://files.pythonhosted.org/packages/ed/5c/b0333b07c51ced77397c2fb0d9826072cea0da9d421aa7e792aa0f8ecc72/nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux2014_x86_64.whl.metadata\n",
            "  Using cached nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-ml-py==12.570.86 (from -r /content/condaenv.chicm1ke.requirements.txt (line 120))\n",
            "  Obtaining dependency information for nvidia-ml-py==12.570.86 from https://files.pythonhosted.org/packages/d8/a8/ec37169be4e2b7063b9076ed3fe0661e87335fbca665eed3f48c415cb234/nvidia_ml_py-12.570.86-py3-none-any.whl.metadata\n",
            "  Using cached nvidia_ml_py-12.570.86-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting nvidia-nvcomp-cu11==4.2.0.11 (from -r /content/condaenv.chicm1ke.requirements.txt (line 121))\n",
            "  Obtaining dependency information for nvidia-nvcomp-cu11==4.2.0.11 from https://files.pythonhosted.org/packages/b3/02/36b2f5ae67a476e122c80c6b862407abea1f49677bf0a31da0a343394977/nvidia_nvcomp_cu11-4.2.0.11-py3-none-manylinux_2_28_x86_64.whl.metadata\n",
            "  Using cached nvidia_nvcomp_cu11-4.2.0.11-py3-none-manylinux_2_28_x86_64.whl.metadata (863 bytes)\n",
            "Collecting nvtx==0.2.11 (from -r /content/condaenv.chicm1ke.requirements.txt (line 122))\n",
            "  Obtaining dependency information for nvtx==0.2.11 from https://files.pythonhosted.org/packages/a8/92/300e0f76a2f3b4ded154b0204a15f7ca9ea3842a0dae90ed1dd8ca1f5350/nvtx-0.2.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Using cached nvtx-0.2.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
            "Collecting overrides==7.4.0 (from -r /content/condaenv.chicm1ke.requirements.txt (line 123))\n",
            "  Obtaining dependency information for overrides==7.4.0 from https://files.pythonhosted.org/packages/da/28/3fa6ef8297302fc7b3844980b6c5dbc71cdbd4b61e9b2591234214d5ab39/overrides-7.4.0-py3-none-any.whl.metadata\n",
            "  Using cached overrides-7.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting pandas==2.0.3 (from -r /content/condaenv.chicm1ke.requirements.txt (line 124))\n",
            "  Obtaining dependency information for pandas==2.0.3 from https://files.pythonhosted.org/packages/e3/59/35a2892bf09ded9c1bf3804461efe772836a5261ef5dfb4e264ce813ff99/pandas-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Using cached pandas-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting pandocfilters==1.5.0 (from -r /content/condaenv.chicm1ke.requirements.txt (line 125))\n",
            "  Obtaining dependency information for pandocfilters==1.5.0 from https://files.pythonhosted.org/packages/5e/a8/878258cffd53202a6cc1903c226cf09e58ae3df6b09f8ddfa98033286637/pandocfilters-1.5.0-py2.py3-none-any.whl.metadata\n",
            "  Using cached pandocfilters-1.5.0-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting panel==1.6.1 (from -r /content/condaenv.chicm1ke.requirements.txt (line 126))\n",
            "  Obtaining dependency information for panel==1.6.1 from https://files.pythonhosted.org/packages/42/11/e98e3b54f4153daeff029522697b69b6b1d7e121487d36095e80b7effcc5/panel-1.6.1-py3-none-any.whl.metadata\n",
            "  Using cached panel-1.6.1-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting param==2.2.0 (from -r /content/condaenv.chicm1ke.requirements.txt (line 127))\n",
            "  Obtaining dependency information for param==2.2.0 from https://files.pythonhosted.org/packages/99/56/370a6636e072a037b52499edd8928942df7f887974fc54444ece5152d26a/param-2.2.0-py3-none-any.whl.metadata\n",
            "  Using cached param-2.2.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting partd==1.4.2 (from -r /content/condaenv.chicm1ke.requirements.txt (line 128))\n",
            "  Obtaining dependency information for partd==1.4.2 from https://files.pythonhosted.org/packages/71/e7/40fb618334dcdf7c5a316c0e7343c5cd82d3d866edc100d98e29bc945ecd/partd-1.4.2-py3-none-any.whl.metadata\n",
            "  Using cached partd-1.4.2-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting pathtools==0.1.2 (from -r /content/condaenv.chicm1ke.requirements.txt (line 129))\n",
            "  Using cached pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting patsy==0.5.3 (from -r /content/condaenv.chicm1ke.requirements.txt (line 130))\n",
            "  Obtaining dependency information for patsy==0.5.3 from https://files.pythonhosted.org/packages/2a/e4/b3263b0e353f2be7b14f044d57874490c9cef1798a435f038683acea5c98/patsy-0.5.3-py2.py3-none-any.whl.metadata\n",
            "  Using cached patsy-0.5.3-py2.py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting petsc4py==3.18.1 (from -r /content/condaenv.chicm1ke.requirements.txt (line 131))\n",
            "  Using cached petsc4py-3.18.1.tar.gz (2.5 MB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting pillow==11.1.0 (from -r /content/condaenv.chicm1ke.requirements.txt (line 132))\n",
            "  Obtaining dependency information for pillow==11.1.0 from https://files.pythonhosted.org/packages/84/7a/cd0c3eaf4a28cb2a74bdd19129f7726277a7f30c4f8424cd27a62987d864/pillow-11.1.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata\n",
            "  Using cached pillow-11.1.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting prometheus-client==0.17.1 (from -r /content/condaenv.chicm1ke.requirements.txt (line 133))\n",
            "  Obtaining dependency information for prometheus-client==0.17.1 from https://files.pythonhosted.org/packages/ad/b3/6e18c89bf6bd120590ea538a62cae16dc763ff2745b18377c4be5495c4aa/prometheus_client-0.17.1-py3-none-any.whl.metadata\n",
            "  Using cached prometheus_client-0.17.1-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting propcache==0.3.0 (from -r /content/condaenv.chicm1ke.requirements.txt (line 134))\n",
            "  Obtaining dependency information for propcache==0.3.0 from https://files.pythonhosted.org/packages/f4/eb/41447de61eb5454891658d0fb9b1d7d35d49a4a5dd2e0c86f2c332e8b7e1/propcache-0.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Using cached propcache-0.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting protobuf==4.24.1 (from -r /content/condaenv.chicm1ke.requirements.txt (line 135))\n",
            "  Obtaining dependency information for protobuf==4.24.1 from https://files.pythonhosted.org/packages/4c/87/59648989ad7f5ba6fe3c7f8abc555183f28559b6f6cd14ad17a3f0d3094f/protobuf-4.24.1-cp37-abi3-manylinux2014_x86_64.whl.metadata\n",
            "  Using cached protobuf-4.24.1-cp37-abi3-manylinux2014_x86_64.whl.metadata (540 bytes)\n",
            "Collecting psutil==5.9.5 (from -r /content/condaenv.chicm1ke.requirements.txt (line 136))\n",
            "  Obtaining dependency information for psutil==5.9.5 from https://files.pythonhosted.org/packages/af/4d/389441079ecef400e2551a3933224885a7bde6b8a4810091d628cdd75afe/psutil-5.9.5-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Using cached psutil-5.9.5-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Collecting ptxcompiler-cu11==0.8.1.post2 (from -r /content/condaenv.chicm1ke.requirements.txt (line 137))\n",
            "  Using cached ptxcompiler_cu11-0.8.1.post2.tar.gz (503 bytes)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Collecting pyarrow==19.0.1 (from -r /content/condaenv.chicm1ke.requirements.txt (line 138))\n",
            "  Obtaining dependency information for pyarrow==19.0.1 from https://files.pythonhosted.org/packages/ef/c9/68ab123ee1528699c4d5055f645ecd1dd68ff93e4699527249d02f55afeb/pyarrow-19.0.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata\n",
            "  Using cached pyarrow-19.0.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting pycparser==2.21 (from -r /content/condaenv.chicm1ke.requirements.txt (line 139))\n",
            "  Obtaining dependency information for pycparser==2.21 from https://files.pythonhosted.org/packages/62/d5/5f610ebe421e85889f2e55e33b7f9a6795bd982198517d912eb1c76e1a53/pycparser-2.21-py2.py3-none-any.whl.metadata\n",
            "  Using cached pycparser-2.21-py2.py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting pyct==0.5.0 (from -r /content/condaenv.chicm1ke.requirements.txt (line 140))\n",
            "  Obtaining dependency information for pyct==0.5.0 from https://files.pythonhosted.org/packages/75/e7/c7c1e9e1b6b23ca1db7af3c6826d57d8da883021f751edcc9c82143b127a/pyct-0.5.0-py2.py3-none-any.whl.metadata\n",
            "  Using cached pyct-0.5.0-py2.py3-none-any.whl.metadata (7.4 kB)\n",
            "\n",
            "Pip subprocess error:\n",
            "ERROR: Ignored the following versions that require a different python version: 0.36.0 Requires-Python >=3.6,<3.10; 0.37.0 Requires-Python >=3.7,<3.10; 0.52.0 Requires-Python >=3.6,<3.9; 0.52.0rc3 Requires-Python >=3.6,<3.9; 0.53.0 Requires-Python >=3.6,<3.10; 0.53.0rc1.post1 Requires-Python >=3.6,<3.10; 0.53.0rc2 Requires-Python >=3.6,<3.10; 0.53.0rc3 Requires-Python >=3.6,<3.10; 0.53.1 Requires-Python >=3.6,<3.10; 0.54.0 Requires-Python >=3.7,<3.10; 0.54.0rc2 Requires-Python >=3.7,<3.10; 0.54.0rc3 Requires-Python >=3.7,<3.10; 0.54.1 Requires-Python >=3.7,<3.10; 1.3.3 Requires-Python >=3.11; 3.5 Requires-Python >=3.11; 3.5rc0 Requires-Python >=3.11\n",
            "ERROR: Could not find a version that satisfies the requirement pyg-lib==0.2.0+pt20cu118 (from versions: none)\n",
            "ERROR: No matching distribution found for pyg-lib==0.2.0+pt20cu118\n",
            "\n",
            "\b\bfailed\n",
            "\n",
            "CondaEnvException: Pip failed\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda init | conda activate GNNenv | pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.0.0+cu118.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wGLr_wXemf0",
        "outputId": "5128e017-8358-4946-ee60-45a1209a0e1b"
      },
      "id": "8wGLr_wXemf0",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CondaError: Run 'conda init' before 'conda activate'\n",
            "\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.0.0+cu118.html\n",
            "Requirement already satisfied: pyg_lib in /usr/local/lib/python3.11/site-packages (0.4.0+pt20cu118)\n",
            "Requirement already satisfied: torch_scatter in /usr/local/lib/python3.11/site-packages (2.1.2+pt20cu118)\n",
            "Requirement already satisfied: torch_sparse in /usr/local/lib/python3.11/site-packages (0.6.18+pt20cu118)\n",
            "Requirement already satisfied: torch_cluster in /usr/local/lib/python3.11/site-packages (1.6.3+pt20cu118)\n",
            "Requirement already satisfied: torch_spline_conv in /usr/local/lib/python3.11/site-packages (1.2.2+pt20cu118)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/site-packages (from torch_sparse) (1.16.2)\n",
            "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.11/site-packages (from scipy->torch_sparse) (2.3.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda init\n",
        "!conda activate GNNenv | pip install torch-geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-9TAU8Zfn_y",
        "outputId": "145532af-9e48-4925-9317-25b739fa7e20"
      },
      "id": "W-9TAU8Zfn_y",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no change     /usr/local/condabin/conda\n",
            "no change     /usr/local/bin/conda\n",
            "no change     /usr/local/bin/conda-env\n",
            "no change     /usr/local/bin/activate\n",
            "no change     /usr/local/bin/deactivate\n",
            "no change     /usr/local/etc/profile.d/conda.sh\n",
            "no change     /usr/local/etc/fish/conf.d/conda.fish\n",
            "no change     /usr/local/shell/condabin/Conda.psm1\n",
            "no change     /usr/local/shell/condabin/conda-hook.ps1\n",
            "no change     /usr/local/lib/python3.11/site-packages/xontrib/conda.xsh\n",
            "no change     /usr/local/etc/profile.d/conda.csh\n",
            "no change     /root/.bashrc\n",
            "No action taken.\n",
            "\n",
            "CondaError: Run 'conda init' before 'conda activate'\n",
            "\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "Collecting aiohttp (from torch-geometric)\n",
            "  Downloading aiohttp-3.12.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting fsspec (from torch-geometric)\n",
            "  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting jinja2 (from torch-geometric)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/site-packages (from torch-geometric) (2.3.3)\n",
            "Collecting psutil>=5.8.0 (from torch-geometric)\n",
            "  Downloading psutil-7.1.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (23 kB)\n",
            "Collecting pyparsing (from torch-geometric)\n",
            "  Downloading pyparsing-3.2.4-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/site-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/site-packages (from torch-geometric) (4.67.1)\n",
            "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp->torch-geometric)\n",
            "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.4.0 (from aiohttp->torch-geometric)\n",
            "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting attrs>=17.3.0 (from aiohttp->torch-geometric)\n",
            "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp->torch-geometric)\n",
            "  Downloading frozenlist-1.7.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->torch-geometric)\n",
            "  Downloading multidict-6.6.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp->torch-geometric)\n",
            "  Downloading propcache-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp->torch-geometric)\n",
            "  Downloading yarl-1.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch-geometric)\n",
            "  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests->torch-geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests->torch-geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests->torch-geometric) (2024.12.14)\n",
            "Collecting typing-extensions>=4.2 (from aiosignal>=1.4.0->aiohttp->torch-geometric)\n",
            "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading psutil-7.1.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (291 kB)\n",
            "Downloading aiohttp-3.12.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
            "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Downloading pyparsing-3.2.4-py3-none-any.whl (113 kB)\n",
            "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
            "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
            "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
            "Downloading frozenlist-1.7.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (235 kB)\n",
            "Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Downloading multidict-6.6.4-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (246 kB)\n",
            "Downloading propcache-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
            "Downloading yarl-1.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (348 kB)\n",
            "Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "Installing collected packages: typing-extensions, pyparsing, psutil, propcache, multidict, MarkupSafe, fsspec, frozenlist, attrs, aiohappyeyeballs, yarl, jinja2, aiosignal, aiohttp, torch-geometric\n",
            "Successfully installed MarkupSafe-3.0.2 aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 attrs-25.3.0 frozenlist-1.7.0 fsspec-2025.9.0 jinja2-3.1.6 multidict-6.6.4 propcache-0.3.2 psutil-7.1.0 pyparsing-3.2.4 torch-geometric-2.6.1 typing-extensions-4.15.0 yarl-1.20.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jmjIDzi7flpF"
      },
      "id": "jmjIDzi7flpF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "source activate GNNenv\n",
        "pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv torch torchvision -f https://data.pyg.org/whl/torch-2.0.0+cu118.html\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bE_WM16-Y8SO",
        "outputId": "00ae1d95-0a34-4ecb-9d35-a13b6347caeb"
      },
      "id": "bE_WM16-Y8SO",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.0.0+cu118.html\n",
            "Collecting pyg_lib\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/pyg_lib-0.4.0%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (2.6 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.6/2.6 MB 2.2 MB/s eta 0:00:00\n",
            "Collecting torch_scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_scatter-2.1.2%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (10.2 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.2/10.2 MB 6.4 MB/s eta 0:00:00\n",
            "Collecting torch_sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_sparse-0.6.18%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (4.9 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.9/4.9 MB 90.8 MB/s eta 0:00:00\n",
            "Collecting torch_cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_cluster-1.6.3%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (3.3 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.3/3.3 MB 105.1 MB/s eta 0:00:00\n",
            "Collecting torch_spline_conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcu118/torch_spline_conv-1.2.2%2Bpt20cu118-cp310-cp310-linux_x86_64.whl (886 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 886.6/886.6 kB 73.8 MB/s eta 0:00:00\n",
            "Collecting torch\n",
            "  Obtaining dependency information for torch from https://files.pythonhosted.org/packages/70/1c/58da560016f81c339ae14ab16c98153d51c941544ae568da3cb5b1ceb572/torch-2.8.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata\n",
            "  Downloading torch-2.8.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Collecting torchvision\n",
            "  Obtaining dependency information for torchvision from https://files.pythonhosted.org/packages/93/f3/3cdf55bbf0f737304d997561c34ab0176222e0496b6743b0feab5995182c/torchvision-0.23.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata\n",
            "  Downloading torchvision-0.23.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/envs/GNNenv/lib/python3.10/site-packages (from torch_sparse) (1.14.0)\n",
            "Collecting filelock (from torch)\n",
            "  Obtaining dependency information for filelock from https://files.pythonhosted.org/packages/42/14/42b2651a2f46b022ccd948bca9f2d5af0fd8929c4eec235b8d6d844fbe67/filelock-3.19.1-py3-none-any.whl.metadata\n",
            "  Downloading filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting typing-extensions>=4.10.0 (from torch)\n",
            "  Obtaining dependency information for typing-extensions>=4.10.0 from https://files.pythonhosted.org/packages/18/67/36e9267722cc04a6b9f15c7f3441c2363321a3ea07da7ae0c0707beb2a9c/typing_extensions-4.15.0-py3-none-any.whl.metadata\n",
            "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting sympy>=1.13.3 (from torch)\n",
            "  Obtaining dependency information for sympy>=1.13.3 from https://files.pythonhosted.org/packages/a2/09/77d55d46fd61b4a135c444fc97158ef34a095e5681d0a6c10b75bf356191/sympy-1.14.0-py3-none-any.whl.metadata\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx (from torch)\n",
            "  Obtaining dependency information for networkx from https://files.pythonhosted.org/packages/b9/54/dd730b32ea14ea797530a4479b2ed46a6fb250f682a9cfb997e968bf0261/networkx-3.4.2-py3-none-any.whl.metadata\n",
            "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch)\n",
            "  Obtaining dependency information for jinja2 from https://files.pythonhosted.org/packages/62/a1/3d680cbfd5f4b8f15abc1d571870c5fc3e594bb582bc3b64ea099db13e56/jinja2-3.1.6-py3-none-any.whl.metadata\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec (from torch)\n",
            "  Obtaining dependency information for fsspec from https://files.pythonhosted.org/packages/47/71/70db47e4f6ce3e5c37a607355f80da8860a33226be640226ac52cb05ef2e/fsspec-2025.9.0-py3-none-any.whl.metadata\n",
            "  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch)\n",
            "  Obtaining dependency information for nvidia-cuda-nvrtc-cu12==12.8.93 from https://files.pythonhosted.org/packages/05/6b/32f747947df2da6994e999492ab306a903659555dddc0fbdeb9d71f75e52/nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch)\n",
            "  Obtaining dependency information for nvidia-cuda-runtime-cu12==12.8.90 from https://files.pythonhosted.org/packages/0d/9b/a997b638fcd068ad6e4d53b8551a7d30fe8b404d6f1804abf1df69838932/nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch)\n",
            "  Obtaining dependency information for nvidia-cuda-cupti-cu12==12.8.90 from https://files.pythonhosted.org/packages/f8/02/2adcaa145158bf1a8295d83591d22e4103dbfd821bcaf6f3f53151ca4ffa/nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch)\n",
            "  Obtaining dependency information for nvidia-cudnn-cu12==9.10.2.21 from https://files.pythonhosted.org/packages/ba/51/e123d997aa098c61d029f76663dedbfb9bc8dcf8c60cbd6adbe42f76d049/nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata\n",
            "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch)\n",
            "  Obtaining dependency information for nvidia-cublas-cu12==12.8.4.1 from https://files.pythonhosted.org/packages/dc/61/e24b560ab2e2eaeb3c839129175fb330dfcfc29e5203196e5541a4c44682/nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata\n",
            "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch)\n",
            "  Obtaining dependency information for nvidia-cufft-cu12==11.3.3.83 from https://files.pythonhosted.org/packages/1f/13/ee4e00f30e676b66ae65b4f08cb5bcbb8392c03f54f2d5413ea99a5d1c80/nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n",
            "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.9.90 (from torch)\n",
            "  Obtaining dependency information for nvidia-curand-cu12==10.3.9.90 from https://files.pythonhosted.org/packages/fb/aa/6584b56dc84ebe9cf93226a5cde4d99080c8e90ab40f0c27bda7a0f29aa1/nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata\n",
            "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch)\n",
            "  Obtaining dependency information for nvidia-cusolver-cu12==11.7.3.90 from https://files.pythonhosted.org/packages/85/48/9a13d2975803e8cf2777d5ed57b87a0b6ca2cc795f9a4f59796a910bfb80/nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata\n",
            "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch)\n",
            "  Obtaining dependency information for nvidia-cusparse-cu12==12.5.8.93 from https://files.pythonhosted.org/packages/c2/f5/e1854cb2f2bcd4280c44736c93550cc300ff4b8c95ebe370d0aa7d2b473d/nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n",
            "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch)\n",
            "  Obtaining dependency information for nvidia-cusparselt-cu12==0.7.1 from https://files.pythonhosted.org/packages/56/79/12978b96bd44274fe38b5dde5cfb660b1d114f70a65ef962bcbbed99b549/nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata\n",
            "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
            "Collecting nvidia-nccl-cu12==2.27.3 (from torch)\n",
            "  Obtaining dependency information for nvidia-nccl-cu12==2.27.3 from https://files.pythonhosted.org/packages/5c/5b/4e4fff7bad39adf89f735f2bc87248c81db71205b62bcc0d5ca5b606b3c3/nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n",
            "  Downloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.8.90 (from torch)\n",
            "  Obtaining dependency information for nvidia-nvtx-cu12==12.8.90 from https://files.pythonhosted.org/packages/a2/eb/86626c1bbc2edb86323022371c39aa48df6fd8b0a1647bc274577f72e90b/nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n",
            "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch)\n",
            "  Obtaining dependency information for nvidia-nvjitlink-cu12==12.8.93 from https://files.pythonhosted.org/packages/f6/74/86a07f1d0f42998ca31312f998bd3b9a7eff7f52378f4f270c8679c77fb9/nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata\n",
            "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch)\n",
            "  Obtaining dependency information for nvidia-cufile-cu12==1.13.1.3 from https://files.pythonhosted.org/packages/bb/fe/1bcba1dfbfb8d01be8d93f07bfc502c93fa23afa6fd5ab3fc7c1df71038a/nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n",
            "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.4.0 (from torch)\n",
            "  Obtaining dependency information for triton==3.4.0 from https://files.pythonhosted.org/packages/62/ee/0ee5f64a87eeda19bbad9bc54ae5ca5b98186ed00055281fd40fb4beb10e/triton-3.4.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata\n",
            "  Downloading triton-3.4.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/envs/GNNenv/lib/python3.10/site-packages (from triton==3.4.0->torch) (68.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/envs/GNNenv/lib/python3.10/site-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/envs/GNNenv/lib/python3.10/site-packages (from torchvision) (11.3.0)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
            "  Obtaining dependency information for mpmath<1.4,>=1.1.0 from https://files.pythonhosted.org/packages/43/e3/7d92a15f894aa0c9c4b49b8ee9ac9850d6e63b03c9c32c0367a13ae62209/mpmath-1.3.0-py3-none-any.whl.metadata\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
            "  Obtaining dependency information for MarkupSafe>=2.0 from https://files.pythonhosted.org/packages/22/35/137da042dfb4720b638d2937c38a9c2df83fe32d20e8c8f3185dbfef05f7/MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Downloading torch-2.8.0-cp310-cp310-manylinux_2_28_x86_64.whl (888.0 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 888.0/888.0 MB 1.3 MB/s eta 0:00:00\n",
            "Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 594.3/594.3 MB 2.4 MB/s eta 0:00:00\n",
            "Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.2/10.2 MB 90.1 MB/s eta 0:00:00\n",
            "Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 88.0/88.0 MB 19.2 MB/s eta 0:00:00\n",
            "Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 954.8/954.8 kB 76.0 MB/s eta 0:00:00\n",
            "Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 706.8/706.8 MB 1.2 MB/s eta 0:00:00\n",
            "Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 193.1/193.1 MB 9.2 MB/s eta 0:00:00\n",
            "Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 73.3 MB/s eta 0:00:00\n",
            "Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 63.6/63.6 MB 26.5 MB/s eta 0:00:00\n",
            "Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 267.5/267.5 MB 6.9 MB/s eta 0:00:00\n",
            "Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 288.2/288.2 MB 4.6 MB/s eta 0:00:00\n",
            "Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 287.2/287.2 MB 6.2 MB/s eta 0:00:00\n",
            "Downloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.4 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 322.4/322.4 MB 3.4 MB/s eta 0:00:00\n",
            "Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 39.3/39.3 MB 40.5 MB/s eta 0:00:00\n",
            "Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 90.0/90.0 kB 15.5 MB/s eta 0:00:00\n",
            "Downloading triton-3.4.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.4 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 155.4/155.4 MB 11.4 MB/s eta 0:00:00\n",
            "Downloading torchvision-0.23.0-cp310-cp310-manylinux_2_28_x86_64.whl (8.6 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.6/8.6 MB 100.6 MB/s eta 0:00:00\n",
            "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.3/6.3 MB 120.8 MB/s eta 0:00:00\n",
            "Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 44.6/44.6 kB 7.4 MB/s eta 0:00:00\n",
            "Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\n",
            "Downloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 199.3/199.3 kB 31.6 MB/s eta 0:00:00\n",
            "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.9/134.9 kB 23.5 MB/s eta 0:00:00\n",
            "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 83.1 MB/s eta 0:00:00\n",
            "Downloading MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20 kB)\n",
            "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 536.2/536.2 kB 53.4 MB/s eta 0:00:00\n",
            "Installing collected packages: nvidia-cusparselt-cu12, mpmath, typing-extensions, triton, torch_spline_conv, torch_scatter, sympy, pyg_lib, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, MarkupSafe, fsspec, filelock, torch_sparse, torch_cluster, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchvision\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.7.1\n",
            "    Uninstalling typing_extensions-4.7.1:\n",
            "      Successfully uninstalled typing_extensions-4.7.1\n",
            "Successfully installed MarkupSafe-3.0.2 filelock-3.19.1 fsspec-2025.9.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.3 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 pyg_lib-0.4.0+pt20cu118 sympy-1.14.0 torch-2.8.0 torch_cluster-1.6.3+pt20cu118 torch_scatter-2.1.2+pt20cu118 torch_sparse-0.6.18+pt20cu118 torch_spline_conv-1.2.2+pt20cu118 torchvision-0.23.0 triton-3.4.0 typing-extensions-4.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "source activate GNNenv\n",
        "pip install torch-geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dODSt2tah0yT",
        "outputId": "72363e37-e9d4-47ce-b25a-246bfb283bcd"
      },
      "id": "dODSt2tah0yT",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-geometric\n",
            "  Obtaining dependency information for torch-geometric from https://files.pythonhosted.org/packages/03/9f/157e913626c1acfb3b19ce000b1a6e4e4fb177c0bc0ea0c67ca5bd714b5a/torch_geometric-2.6.1-py3-none-any.whl.metadata\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 63.1/63.1 kB 7.1 MB/s eta 0:00:00\n",
            "Collecting aiohttp (from torch-geometric)\n",
            "  Obtaining dependency information for aiohttp from https://files.pythonhosted.org/packages/20/43/2bd482ebe2b126533e8755a49b128ec4e58f1a3af56879a3abdb7b42c54f/aiohttp-3.12.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading aiohttp-3.12.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/envs/GNNenv/lib/python3.10/site-packages (from torch-geometric) (2025.9.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/envs/GNNenv/lib/python3.10/site-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/envs/GNNenv/lib/python3.10/site-packages (from torch-geometric) (1.25.2)\n",
            "Collecting psutil>=5.8.0 (from torch-geometric)\n",
            "  Obtaining dependency information for psutil>=5.8.0 from https://files.pythonhosted.org/packages/9d/de/04c8c61232f7244aa0a4b9a9fbd63a89d5aeaf94b2fc9d1d16e2faa5cbb0/psutil-7.1.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading psutil-7.1.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (23 kB)\n",
            "Requirement already satisfied: pyparsing in /usr/local/envs/GNNenv/lib/python3.10/site-packages (from torch-geometric) (3.2.4)\n",
            "Requirement already satisfied: requests in /usr/local/envs/GNNenv/lib/python3.10/site-packages (from torch-geometric) (2.31.0)\n",
            "Collecting tqdm (from torch-geometric)\n",
            "  Obtaining dependency information for tqdm from https://files.pythonhosted.org/packages/d0/30/dc54f88dd4a2b5dc8a0279bdd7270e735851848b762aeb1c1184ed1f6b14/tqdm-4.67.1-py3-none-any.whl.metadata\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.7/57.7 kB 8.7 MB/s eta 0:00:00\n",
            "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp->torch-geometric)\n",
            "  Obtaining dependency information for aiohappyeyeballs>=2.5.0 from https://files.pythonhosted.org/packages/0f/15/5bf3b99495fb160b63f95972b81750f18f7f4e02ad051373b669d17d44f2/aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata\n",
            "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.4.0 (from aiohttp->torch-geometric)\n",
            "  Obtaining dependency information for aiosignal>=1.4.0 from https://files.pythonhosted.org/packages/fb/76/641ae371508676492379f16e2fa48f4e2c11741bd63c48be4b12a6b09cba/aiosignal-1.4.0-py3-none-any.whl.metadata\n",
            "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting async-timeout<6.0,>=4.0 (from aiohttp->torch-geometric)\n",
            "  Obtaining dependency information for async-timeout<6.0,>=4.0 from https://files.pythonhosted.org/packages/fe/ba/e2081de779ca30d473f21f5b30e0e737c438205440784c7dfc81efc2b029/async_timeout-5.0.1-py3-none-any.whl.metadata\n",
            "  Using cached async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting attrs>=17.3.0 (from aiohttp->torch-geometric)\n",
            "  Obtaining dependency information for attrs>=17.3.0 from https://files.pythonhosted.org/packages/77/06/bb80f5f86020c4551da315d78b3ab75e8228f89f0162f2c3a819e407941a/attrs-25.3.0-py3-none-any.whl.metadata\n",
            "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp->torch-geometric)\n",
            "  Obtaining dependency information for frozenlist>=1.1.1 from https://files.pythonhosted.org/packages/13/47/f9179ee5ee4f55629e4f28c660b3fdf2775c8bfde8f9c53f2de2d93f52a9/frozenlist-1.7.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading frozenlist-1.7.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->torch-geometric)\n",
            "  Obtaining dependency information for multidict<7.0,>=4.5 from https://files.pythonhosted.org/packages/05/a9/48d1bd111fc2f8fb98b2ed7f9a115c55a9355358432a19f53c0b74d8425d/multidict-6.6.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata\n",
            "  Downloading multidict-6.6.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp->torch-geometric)\n",
            "  Obtaining dependency information for propcache>=0.2.0 from https://files.pythonhosted.org/packages/7c/bb/38fd08b278ca85cde36d848091ad2b45954bc5f15cce494bb300b9285831/propcache-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading propcache-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp->torch-geometric)\n",
            "  Obtaining dependency information for yarl<2.0,>=1.17.0 from https://files.pythonhosted.org/packages/65/94/e21269718349582eee81efc5c1c08ee71c816bfc1585b77d0ec3f58089eb/yarl-1.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading yarl-1.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 73.9/73.9 kB 11.5 MB/s eta 0:00:00\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/envs/GNNenv/lib/python3.10/site-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/envs/GNNenv/lib/python3.10/site-packages (from requests->torch-geometric) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/envs/GNNenv/lib/python3.10/site-packages (from requests->torch-geometric) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/envs/GNNenv/lib/python3.10/site-packages (from requests->torch-geometric) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/envs/GNNenv/lib/python3.10/site-packages (from requests->torch-geometric) (2025.1.31)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/envs/GNNenv/lib/python3.10/site-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 69.5 MB/s eta 0:00:00\n",
            "Downloading psutil-7.1.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (291 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 291.2/291.2 kB 43.9 MB/s eta 0:00:00\n",
            "Downloading aiohttp-3.12.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 87.5 MB/s eta 0:00:00\n",
            "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.5/78.5 kB 15.6 MB/s eta 0:00:00\n",
            "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
            "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
            "Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
            "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 63.8/63.8 kB 11.9 MB/s eta 0:00:00\n",
            "Downloading frozenlist-1.7.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (222 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 222.9/222.9 kB 39.9 MB/s eta 0:00:00\n",
            "Downloading multidict-6.6.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (241 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 241.6/241.6 kB 42.2 MB/s eta 0:00:00\n",
            "Downloading propcache-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (198 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 198.3/198.3 kB 35.7 MB/s eta 0:00:00\n",
            "Downloading yarl-1.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 326.1/326.1 kB 46.8 MB/s eta 0:00:00\n",
            "Installing collected packages: tqdm, psutil, propcache, multidict, frozenlist, attrs, async-timeout, aiohappyeyeballs, yarl, aiosignal, aiohttp, torch-geometric\n",
            "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 async-timeout-5.0.1 attrs-25.3.0 frozenlist-1.7.0 multidict-6.6.4 propcache-0.3.2 psutil-7.1.0 torch-geometric-2.6.1 tqdm-4.67.1 yarl-1.20.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "source activate GNNenv\n",
        "conda install -c \"nvidia/label/cuda-11.8.0\" cuda-toolkit cudnn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAP7TFc5jwWB",
        "outputId": "3223d0bb-77da-4dd0-c865-b10bd8f4b8d1"
      },
      "id": "VAP7TFc5jwWB",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Process is terminated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "source activate GNNenv\n",
        "pip install nvidia-cuda-runtime-cu11"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwDodEs6iuyy",
        "outputId": "56664be3-9884-4b06-c393-571f8a2189ca"
      },
      "id": "MwDodEs6iuyy",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-cuda-runtime-cu11\n",
            "  Obtaining dependency information for nvidia-cuda-runtime-cu11 from https://files.pythonhosted.org/packages/a6/ec/a540f28b31de7bc1ed49eecc72035d4cb77db88ead1d42f7bfa5ae407ac6/nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux2014_x86_64.whl.metadata\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Downloading nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux2014_x86_64.whl (875 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 875.6/875.6 kB 48.7 MB/s eta 0:00:00\n",
            "Installing collected packages: nvidia-cuda-runtime-cu11\n",
            "Successfully installed nvidia-cuda-runtime-cu11-11.8.89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "source activate GNNenv\n",
        "pip install geopandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PsxzN4-iXjc",
        "outputId": "bba328f7-6902-418f-a6db-285f3b6e7f53"
      },
      "id": "6PsxzN4-iXjc",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting geopandas\n",
            "  Obtaining dependency information for geopandas from https://files.pythonhosted.org/packages/0b/70/d5cd0696eff08e62fdbdebe5b46527facb4e7220eabe0ac6225efab50168/geopandas-1.1.1-py3-none-any.whl.metadata\n",
            "  Downloading geopandas-1.1.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/envs/GNNenv/lib/python3.10/site-packages (from geopandas) (1.25.2)\n",
            "Collecting pyogrio>=0.7.2 (from geopandas)\n",
            "  Obtaining dependency information for pyogrio>=0.7.2 from https://files.pythonhosted.org/packages/15/87/7a180f3fadb9a388312e789feee023cd20d1d589724ef093ebee4d784b9a/pyogrio-0.11.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata\n",
            "  Downloading pyogrio-0.11.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/envs/GNNenv/lib/python3.10/site-packages (from geopandas) (23.1)\n",
            "Collecting pandas>=2.0.0 (from geopandas)\n",
            "  Obtaining dependency information for pandas>=2.0.0 from https://files.pythonhosted.org/packages/c4/6a/40b043b06e08df1ea1b6d20f0e0c2f2c4ec8c4f07d1c92948273d943a50b/pandas-2.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading pandas-2.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 91.2/91.2 kB 10.7 MB/s eta 0:00:00\n",
            "Collecting pyproj>=3.5.0 (from geopandas)\n",
            "  Obtaining dependency information for pyproj>=3.5.0 from https://files.pythonhosted.org/packages/76/a5/c6e11b9a99ce146741fb4d184d5c468446c6d6015b183cae82ac822a6cfa/pyproj-3.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading pyproj-3.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
            "Collecting shapely>=2.0.0 (from geopandas)\n",
            "  Obtaining dependency information for shapely>=2.0.0 from https://files.pythonhosted.org/packages/a9/4f/6c9bb4bd7b1a14d7051641b9b479ad2a643d5cbc382bcf5bd52fd0896974/shapely-2.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading shapely-2.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/envs/GNNenv/lib/python3.10/site-packages (from pandas>=2.0.0->geopandas) (2.9.0.post0)\n",
            "Collecting pytz>=2020.1 (from pandas>=2.0.0->geopandas)\n",
            "  Obtaining dependency information for pytz>=2020.1 from https://files.pythonhosted.org/packages/81/c4/34e93fe5f5429d7570ec1fa436f1986fb1f00c3e0f43a589fe2bbcd22c3f/pytz-2025.2-py2.py3-none-any.whl.metadata\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas>=2.0.0->geopandas)\n",
            "  Obtaining dependency information for tzdata>=2022.7 from https://files.pythonhosted.org/packages/5c/23/c7abc0ca0a1526a0774eca151daeb8de62ec457e77262b66b359c3c7679e/tzdata-2025.2-py2.py3-none-any.whl.metadata\n",
            "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/envs/GNNenv/lib/python3.10/site-packages (from pyogrio>=0.7.2->geopandas) (2025.1.31)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/envs/GNNenv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->geopandas) (1.16.0)\n",
            "Downloading geopandas-1.1.1-py3-none-any.whl (338 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 338.4/338.4 kB 44.6 MB/s eta 0:00:00\n",
            "Downloading pandas-2.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.3/12.3 MB 84.5 MB/s eta 0:00:00\n",
            "Downloading pyogrio-0.11.1-cp310-cp310-manylinux_2_28_x86_64.whl (27.5 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 27.5/27.5 MB 39.3 MB/s eta 0:00:00\n",
            "Downloading pyproj-3.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.3 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.3/9.3 MB 104.1 MB/s eta 0:00:00\n",
            "Downloading shapely-2.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.1/3.1 MB 108.4 MB/s eta 0:00:00\n",
            "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 509.2/509.2 kB 48.4 MB/s eta 0:00:00\n",
            "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 347.8/347.8 kB 45.2 MB/s eta 0:00:00\n",
            "Installing collected packages: pytz, tzdata, shapely, pyproj, pyogrio, pandas, geopandas\n",
            "Successfully installed geopandas-1.1.1 pandas-2.3.2 pyogrio-0.11.1 pyproj-3.7.1 pytz-2025.2 shapely-2.1.1 tzdata-2025.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install torch_geometric pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.8.0+cu126.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NA9eQw2BZzma",
        "outputId": "ac9b706c-5600-454b-a89e-c0702f96b583"
      },
      "id": "NA9eQw2BZzma",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.8.0+cu126.html\n",
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.12/dist-packages (2.6.1)\n",
            "Requirement already satisfied: pyg_lib in /usr/local/lib/python3.12/dist-packages (0.4.0+pt28cu126)\n",
            "Requirement already satisfied: torch_scatter in /usr/local/lib/python3.12/dist-packages (2.1.2+pt28cu126)\n",
            "Requirement already satisfied: torch_sparse in /usr/local/lib/python3.12/dist-packages (0.6.18+pt28cu126)\n",
            "Requirement already satisfied: torch_cluster in /usr/local/lib/python3.12/dist-packages (1.6.3+pt28cu126)\n",
            "Requirement already satisfied: torch_spline_conv in /usr/local/lib/python3.12/dist-packages (1.2.2+pt28cu126)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.12.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch_sparse) (1.16.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2025.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch_geometric) (4.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "39bc9f88",
      "metadata": {
        "id": "39bc9f88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73ee32f8-ebe2-4bbf-811c-aa25e206d357"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/envs/GNNenv/lib/python3.10/site-packages/torch_geometric/typing.py:68: UserWarning: An issue occurred while importing 'pyg-lib'. Disabling its usage. Stacktrace: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
            "  warnings.warn(f\"An issue occurred while importing 'pyg-lib'. \"\n",
            "/usr/local/envs/GNNenv/lib/python3.10/site-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /usr/local/envs/GNNenv/lib/python3.10/site-packages/torch_scatter/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
            "/usr/local/envs/GNNenv/lib/python3.10/site-packages/torch_geometric/typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: /usr/local/envs/GNNenv/lib/python3.10/site-packages/torch_cluster/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n",
            "/usr/local/envs/GNNenv/lib/python3.10/site-packages/torch_geometric/typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: /usr/local/envs/GNNenv/lib/python3.10/site-packages/torch_spline_conv/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
            "  warnings.warn(\n",
            "/usr/local/envs/GNNenv/lib/python3.10/site-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /usr/local/envs/GNNenv/lib/python3.10/site-packages/torch_sparse/_version_cuda.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "source activate GNNenv\n",
        "python\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import pickle\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch_geometric.data import HeteroData, Batch\n",
        "import torch.nn as nn\n",
        "import torch_geometric.nn as geometric_nn\n",
        "from torch_geometric.nn import GATv2Conv, GraphConv\n",
        "from datetime import date\n",
        "import geopandas as gpd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6bc6592c",
      "metadata": {
        "id": "6bc6592c"
      },
      "source": [
        "### Utils"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/Demo_t2m/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xk6Zr9Sqbl0b",
        "outputId": "0e35d231-4d42-4fad-9447-20a72e1f071d"
      },
      "id": "Xk6Zr9Sqbl0b",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data  demo_GNN4CD_t2m.ipynb  ne_10m_admin_0_countries  training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH='/content/drive/MyDrive/Demo_t2m/'"
      ],
      "metadata": {
        "id": "jNB2gDPpb1kP"
      },
      "id": "jNB2gDPpb1kP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5e60624",
      "metadata": {
        "id": "a5e60624"
      },
      "outputs": [],
      "source": [
        "def set_seed_everything(seed):\n",
        "    r\"\"\"Sets the seed for generating random numbers\n",
        "    Args:\n",
        "        seed (int): the desired seed\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def standardize_input(x_low, x_high, means_low, stds_low, means_high, stds_high):\n",
        "\n",
        "    print(f'\\nStandardizing the low-res input data.')\n",
        "\n",
        "    x_low_standard = torch.empty_like(x_low, dtype=torch.float32)\n",
        "    for var in range(x_low.shape[2]):\n",
        "        print(f'Done var {var}.')\n",
        "        x_low_standard[:,:,var,:] = (x_low[:,:,var,:]-means_low[var]) / stds_low[var]  # num_nodes, time, vars, levels\n",
        "\n",
        "\n",
        "    print(f'\\nStandardizing the high-res input data')\n",
        "\n",
        "    x_high_standard = (x_high - means_high) / stds_high\n",
        "    print(f'Done.')\n",
        "\n",
        "    return x_low_standard, x_high_standard\n",
        "\n",
        "\n",
        "def date_to_idxs(year_start, month_start, day_start, year_end, month_end, day_end,\n",
        "                 first_year, first_month=1, first_day=1):\n",
        "    r'''\n",
        "    Computes the start and end idxs crrespnding to the specified period, with respect to a\n",
        "    reference date.\n",
        "    Args:\n",
        "        year_start (int): year at which period starts\n",
        "        month_start (int): month at which period starts\n",
        "        day_start (int): day at which period starts\n",
        "        year_end (int): year at which period ends\n",
        "        month_end (int): month at which period ends\n",
        "        day_end (int): day at which period ends\n",
        "        first_year (int): reference year to compute the idxs\n",
        "    Returns:\n",
        "        The start and end idxs for the period\n",
        "    '''\n",
        "\n",
        "    start_idx = (date(int(year_start), int(month_start), int(day_start)) - date(int(first_year), int(first_month), int(first_day))).days * 24\n",
        "    end_idx = (date(int(year_end), int(month_end), int(day_end)) - date(int(first_year), int(first_month), int(first_day))).days * 24 + 24\n",
        "\n",
        "    return start_idx, end_idx\n",
        "\n",
        "def discrete_cmap(N, base_cmap):\n",
        "    \"\"\"Create an N-bin discrete colormap from the specified input map\"\"\"\n",
        "\n",
        "    # Note that if base_cmap is a string or None, you can simply do\n",
        "    #    return plt.cm.get_cmap(base_cmap, N)\n",
        "    # The following works for string, None, or a colormap instance:\n",
        "\n",
        "    base = matplotlib.colormaps[base_cmap]\n",
        "    color_list = base(np.linspace(0, 1, N))\n",
        "    cmap_name = base.name + str(N)\n",
        "    return base.from_list(cmap_name, color_list, N)\n",
        "\n",
        "class Dataset_Graph(Dataset):\n",
        "    r\"\"\"Dataset class inspired by the StaticGraphTemporalSignal class of pytorch\n",
        "        geometric designed for temporal signals defined on a static graph\n",
        "    \"\"\"\n",
        "    def __init__(self, graph, targets, **kwargs):\n",
        "        self.graph = graph\n",
        "        self.targets = targets\n",
        "        self.additional_feature_keys = []\n",
        "        for key, value in kwargs.items():\n",
        "            setattr(self, key, value)\n",
        "            self.additional_feature_keys.append(key)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.graph['low'].x.shape[1] # time dimension\n",
        "\n",
        "    def _get_features(self, time_index: int):\n",
        "        x_low = self.graph['low'].x[:,time_index-24:time_index+1,:]\n",
        "        x_low = x_low.flatten(start_dim=2, end_dim=-1)\n",
        "        return x_low\n",
        "\n",
        "    def _get_target(self, time_index: int):\n",
        "        return self.targets[:,time_index]\n",
        "\n",
        "    def _get_train_mask(self, target: torch.tensor):\n",
        "        return ~torch.isnan(target)\n",
        "\n",
        "    def _get_additional_feature(self, time_index: int, feature_key: str):\n",
        "        feature = getattr(self, feature_key)[:,time_index]\n",
        "        return feature\n",
        "\n",
        "    def _get_additional_features(self, time_index: int):\n",
        "        additional_features = {\n",
        "            key: self._get_additional_feature(time_index, key)\n",
        "            for key in self.additional_feature_keys\n",
        "        }\n",
        "        return additional_features\n",
        "\n",
        "    def set_t_offset(self, t_offset: int):\n",
        "        self.t_offset = t_offset\n",
        "\n",
        "    def __getitem__(self, time_index: int):\n",
        "        x_low = self._get_features(time_index)\n",
        "        y = self._get_target(time_index) if self.targets is not None else None\n",
        "        train_mask = self._get_train_mask(y) if y is not None else None\n",
        "\n",
        "        additional_features = self._get_additional_features(time_index)\n",
        "\n",
        "        # Create the graph object\n",
        "        graph = HeteroData()\n",
        "\n",
        "        for key, value in additional_features.items():\n",
        "            if value.shape[0] == self.graph['high'].x.shape[0]:\n",
        "                graph['high'][key] = value\n",
        "            elif value.shape[0] == self.graph['low'].x.shape[0]:\n",
        "                graph['low'][key] = value\n",
        "\n",
        "        graph['high'].y = y\n",
        "        graph['high'].train_mask = train_mask\n",
        "        graph.num_nodes = self.graph.num_nodes\n",
        "        graph['high'].num_nodes = self.graph['high'].num_nodes\n",
        "        graph['low'].num_nodes = self.graph['low'].num_nodes\n",
        "        graph.t = time_index - self.t_offset\n",
        "\n",
        "        for edge_key in self.graph.edge_types:\n",
        "            if 'edge_index' in self.graph[edge_key]:  # Copy edge_index if it exists\n",
        "                graph[edge_key].edge_index = self.graph[edge_key].edge_index\n",
        "            if 'edge_attr' in self.graph[edge_key]:  # Copy edge_attr if it exists\n",
        "                graph[edge_key].edge_attr = self.graph[edge_key].edge_attr\n",
        "\n",
        "        graph['low'].x = x_low # low resolution input features\n",
        "        graph['high'].x = self.graph['high'].x # static high resolution input features\n",
        "\n",
        "        graph['high'].lon = self.graph['high'].lon\n",
        "        graph['high'].lat = self.graph['high'].lat\n",
        "        graph['low'].lon = self.graph['low'].lon\n",
        "        graph['low'].lat = self.graph['low'].lat\n",
        "\n",
        "        return graph\n",
        "\n",
        "\n",
        "class Iterable_Graph(object):\n",
        "\n",
        "    def __init__(self, dataset_graph, shuffle, idxs_vector=None, t_offset=0):\n",
        "        self.dataset_graph = dataset_graph\n",
        "        self.dataset_graph.set_t_offset(t_offset)\n",
        "        self.shuffle = shuffle\n",
        "        self.idxs_vector = idxs_vector\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.idxs_vector)\n",
        "\n",
        "    def __next__(self):\n",
        "        if self.prog_idx < self.idxs_vector.shape[0]:\n",
        "            self.idx = self.sampling_vector[self.prog_idx].item()\n",
        "            self.prog_idx = self.prog_idx + 1\n",
        "            return self.idx\n",
        "        else:\n",
        "            self.prog_idx = 0\n",
        "            self.idx = 0\n",
        "            raise StopIteration\n",
        "\n",
        "    def __iter__(self):\n",
        "        self.prog_idx = 0\n",
        "        self.idx = 0\n",
        "        if self.idxs_vector is not None:\n",
        "            if self.shuffle:\n",
        "                rnd_idxs = torch.randperm(self.idxs_vector.shape[0])\n",
        "                self.sampling_vector = self.idxs_vector[rnd_idxs].view(self.idxs_vector.size())\n",
        "            else:\n",
        "                self.sampling_vector = self.idxs_vector\n",
        "        else:\n",
        "            if self.shuffle:\n",
        "                self.sampling_vector = torch.randperm(len(self)-24) + 24 # from 24 to len\n",
        "            else:\n",
        "                self.sampling_vector = torch.arange(24, len(self))\n",
        "        return self\n",
        "\n",
        "\n",
        "def custom_collate_fn_graph(batch_list):\n",
        "    return Batch.from_data_list(batch_list)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODEL: GNN4CD-Rall"
      ],
      "metadata": {
        "id": "9zJ83v4ZbLuy"
      },
      "id": "9zJ83v4ZbLuy"
    },
    {
      "cell_type": "code",
      "source": [
        "class GNN4CD_model(nn.Module):\n",
        "\n",
        "    def __init__(self, encoding_dim=128, seq_l=25, h_in=4*5, h_hid=4*5, n_layers=2, high_in=1, low2high_out=64, high_out=64):\n",
        "        super(GNN4CD_model, self).__init__()\n",
        "\n",
        "        # input shape (N,L,Hin)\n",
        "        self.rnn = nn.Sequential(\n",
        "            nn.GRU(h_in, h_hid, n_layers, batch_first=True),\n",
        "        )\n",
        "\n",
        "        self.dense = nn.Sequential(\n",
        "            nn.Linear(h_in*seq_l, encoding_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.downscaler = geometric_nn.Sequential('x, edge_index', [\n",
        "            (GraphConv((encoding_dim, high_in), out_channels=low2high_out, aggr='mean'), 'x, edge_index -> x')\n",
        "            ])\n",
        "\n",
        "        self.processor = geometric_nn.Sequential('x, edge_index', [\n",
        "            (geometric_nn.BatchNorm(low2high_out), 'x -> x'),\n",
        "            (GATv2Conv(in_channels=low2high_out, out_channels=high_out, heads=2, dropout=0.2, aggr='mean', add_self_loops=True, bias=True), 'x, edge_index -> x'),\n",
        "            (geometric_nn.BatchNorm(high_out*2), 'x -> x'),\n",
        "            nn.ReLU(),\n",
        "            (GATv2Conv(in_channels=high_out*2, out_channels=high_out, heads=2, dropout=0.2, aggr='mean', add_self_loops=True, bias=True),'x, edge_index -> x'),\n",
        "            (geometric_nn.BatchNorm(high_out*2), 'x -> x'),\n",
        "            nn.ReLU(),\n",
        "            (GATv2Conv(in_channels=high_out*2, out_channels=high_out, heads=2, dropout=0.2, aggr='mean', add_self_loops=True, bias=True),'x, edge_index -> x'),\n",
        "            (geometric_nn.BatchNorm(high_out*2), 'x -> x'),\n",
        "            nn.ReLU(),\n",
        "            (GATv2Conv(in_channels=high_out*2, out_channels=high_out, heads=2, dropout=0.2, aggr='mean', add_self_loops=True, bias=True),'x, edge_index -> x'),\n",
        "            (geometric_nn.BatchNorm(high_out*2), 'x -> x'),\n",
        "            nn.ReLU(),\n",
        "            (GATv2Conv(in_channels=high_out*2, out_channels=high_out, heads=1, dropout=0.0, aggr='mean', add_self_loops=True, bias=True), 'x, edge_index -> x'),\n",
        "            nn.ReLU(),\n",
        "            ])\n",
        "\n",
        "        self.predictor = nn.Sequential(\n",
        "            nn.Linear(high_out, high_out),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(high_out, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1)\n",
        "            )\n",
        "\n",
        "    def forward(self, data, inference=False):\n",
        "        encod_rnn, _ = self.rnn(data.x_dict['low']) # out, h\n",
        "        encod_rnn = encod_rnn.flatten(start_dim=1)\n",
        "        encod_rnn = self.dense(encod_rnn)\n",
        "        encod_low2high  = self.downscaler((encod_rnn, data.x_dict['high']), data[\"low\", \"to\", \"high\"].edge_index)\n",
        "        encod_high = self.processor(encod_low2high , data.edge_index_dict[('high','within','high')])\n",
        "        x_high = self.predictor(encod_high)\n",
        "\n",
        "        if inference:\n",
        "            data['high'].x_high = x_high\n",
        "            data._slice_dict['high']['x_high'] = data._slice_dict['high']['y']\n",
        "            data._inc_dict['high']['x_high'] = data._inc_dict['high']['y']\n",
        "            data = data.to_data_list()\n",
        "            x_high = [data_i['high'].x_high for data_i in data]\n",
        "\n",
        "        return x_high"
      ],
      "metadata": {
        "id": "dgnRirOUbLHl"
      },
      "id": "dgnRirOUbLHl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting functionalities"
      ],
      "metadata": {
        "id": "js8TGikDa9MB"
      },
      "id": "js8TGikDa9MB"
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_pdf(y_pred, y, range, ylim, xlabel, pred_label=\"predictions\",\n",
        "             target_label=\"ground truth\", fontsize=16, suptitle=None):\n",
        "\n",
        "    plt.rcParams.update({'font.size': fontsize})\n",
        "\n",
        "    y_pred = y_pred.flatten()\n",
        "    y = y.flatten()\n",
        "\n",
        "    hist_y_pred, bin_edges_y_pred = np.histogram(y_pred, bins=np.arange(range[0],range[1],range[2]).astype(np.float32), density=False)\n",
        "    hist_y, bin_edges_y = np.histogram(y, bins=np.arange(range[0],range[1],range[2]).astype(np.float32), density=False)\n",
        "\n",
        "    Ntot_y_pred = hist_y_pred.sum()\n",
        "    Ntot_y = hist_y.sum()\n",
        "\n",
        "    bin_edges_y_pred_centre = (bin_edges_y_pred[:-1] + bin_edges_y_pred[1:]) / 2\n",
        "    bin_edges_y_centre = (bin_edges_y[:-1] + bin_edges_y[1:]) / 2\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(6,6))\n",
        "    plt.fill_between(bin_edges_y_centre,hist_y/Ntot_y, color='grey', step=\"mid\", alpha=0.25, label=target_label, zorder=2)\n",
        "    ax.step(bin_edges_y_pred_centre, hist_y_pred/Ntot_y_pred, color='darkturquoise', where=\"mid\", linewidth=1, label=pred_label, zorder=3)\n",
        "    l = plt.legend(loc='upper right', facecolor='white', framealpha=1, fontsize=fontsize)\n",
        "    if ylim is not None:\n",
        "        ax.set_ylim(ylim)\n",
        "    ax.set_xlabel(xlabel, fontsize=fontsize)\n",
        "    ax.set_ylabel('frequency', fontsize=fontsize)\n",
        "\n",
        "    if suptitle is not None:\n",
        "        plt.suptitle(suptitle, y=0.95)\n",
        "    plt.show()\n",
        "\n",
        "def plot_diurnal_cycles(y_pred, y, idxs_seasons, aggr=np.nanmean, fontsize=16, figsize=(8,9),\n",
        "                        xlim=[0,24], ylim=None, ylablel=\"[°C]\", suptitle=None,\n",
        "                       text_list = ['DJF', 'MAM', 'JJA', 'SON']):\n",
        "\n",
        "    plt.rcParams.update({'font.size': fontsize})\n",
        "    fig, ax = plt.subplots(nrows=1, ncols=4, figsize=figsize)\n",
        "\n",
        "    for s in range(4):\n",
        "        idxs = idxs_seasons[s]\n",
        "        y_pred_s = y_pred[:,idxs]\n",
        "        y_s = y[:,idxs]\n",
        "        y_pred_daily_cycles = np.zeros(24)\n",
        "        y_daily_cycles = np.zeros(24)\n",
        "        # axi = ax[s//2, s%2]\n",
        "        axi = ax[s]\n",
        "        for i in range(0,24):\n",
        "            y_pred_daily_cycles[i] = aggr(y_pred_s[:,i::24])\n",
        "            y_daily_cycles[i] = aggr(y_s[:,i::24])\n",
        "        n = 25\n",
        "        vmin=min(y_pred_daily_cycles.min(), y_daily_cycles.min())\n",
        "        vmax=min(y_pred_daily_cycles.max(), y_daily_cycles.max())\n",
        "        axi.plot(range(1,n), y_pred_daily_cycles, label='predictions', linestyle='-', linewidth=2, color='red')\n",
        "        axi.plot(range(1,n), y_daily_cycles, label='ground truth', linestyle=':', linewidth=2, color='black')\n",
        "        axi.set_ylabel(ylablel, fontsize=fontsize)\n",
        "        axi.set_xlabel(\"time [h]\", fontsize=fontsize)\n",
        "        axi.set_xlim(xlim)\n",
        "        if ylim is not None:\n",
        "            axi.set_ylim(ylim)\n",
        "        else:\n",
        "            axi.set_ylim([vmin-2, vmax+2])\n",
        "        axi.set_xticks(ticks=range(0,n,6))\n",
        "        axi.set_title(text_list[s], fontsize=fontsize+2)\n",
        "        axi.grid(which='major', color='lightgrey')\n",
        "    ax[0].legend(loc='upper left', prop={'size': fontsize})\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if suptitle is not None:\n",
        "        plt.suptitle(suptitle, y=1.1)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "def rmse(y, y_pred):\n",
        "    return np.sqrt(np.nanmean((y - y_pred)**2, axis=1))"
      ],
      "metadata": {
        "id": "P7D_hulia8yZ"
      },
      "id": "P7D_hulia8yZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "53253da5",
      "metadata": {
        "id": "53253da5"
      },
      "source": [
        "### Load the target, the graph file and preprocess the input data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4ce1ea9",
      "metadata": {
        "id": "c4ce1ea9"
      },
      "outputs": [],
      "source": [
        "#path=\"/leonardo_work/ICT25_ESP/SHARED/Demo_t2m/data/\"\n",
        "path = DATA_PATH + 'data/'\n",
        "target_file=\"target.pkl\"\n",
        "graph_file=\"graph.pkl\"\n",
        "\n",
        "#train_path=\"/leonardo_work/ICT25_ESP/SHARED/Demo_t2m/training/\"\n",
        "train_path = DATA_PATH + 'training/'\n",
        "epoch=\"49\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35e3c40d",
      "metadata": {
        "id": "35e3c40d"
      },
      "outputs": [],
      "source": [
        "# Load the target\n",
        "with open(path+target_file, 'rb') as f:\n",
        "    target = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1e19627",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1e19627",
        "outputId": "49f4a4fa-aa20-4901-88fd-ff8b6246ff72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Standardizing the low-res input data.\n",
            "Done var 0.\n",
            "Done var 1.\n",
            "Done var 2.\n",
            "Done var 3.\n",
            "\n",
            "Standardizing the high-res input data\n",
            "Done.\n"
          ]
        }
      ],
      "source": [
        "# Load the Pyg graph object\n",
        "with open(path+graph_file, 'rb') as f:\n",
        "    graph = pickle.load(f)\n",
        "\n",
        "# Load the input data statistics used during training\n",
        "with open(train_path + \"means_low.pkl\", 'rb') as f:\n",
        "    means_low = pickle.load(f)\n",
        "with open(train_path + \"stds_low.pkl\", 'rb') as f:\n",
        "    stds_low = pickle.load(f)\n",
        "with open(train_path + \"means_high.pkl\", 'rb') as f:\n",
        "    means_high = pickle.load(f)\n",
        "with open(train_path + \"stds_high.pkl\", 'rb') as f:\n",
        "    stds_high = pickle.load(f)\n",
        "\n",
        "# Standardize the low-res and high-res input features\n",
        "features_low, features_high = standardize_input(graph[\"low\"].x, graph[\"high\"].x, means_low, stds_low, means_high, stds_high)\n",
        "\n",
        "# Update the graph initial node features with the standardized values\n",
        "graph[\"low\"].x = features_low\n",
        "graph[\"high\"].x = features_high\n",
        "\n",
        "graph['low'].x = torch.flatten(graph['low'].x, start_dim=2, end_dim=-1)   # num_nodes, time, vars*levels"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7cf3bad8",
      "metadata": {
        "id": "7cf3bad8"
      },
      "source": [
        "Let's look at the Pyg HeteroData object which represents our graph!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d74c8a7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d74c8a7",
        "outputId": "8d52468a-06c3-47c6-ae90-841c3d022241"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  low={\n",
              "    x=[720, 140256, 20],\n",
              "    lat=[720],\n",
              "    lon=[720],\n",
              "    num_nodes=720,\n",
              "  },\n",
              "  high={\n",
              "    lat=[14036],\n",
              "    lon=[14036],\n",
              "    x=[14036, 1],\n",
              "    num_nodes=14036,\n",
              "  },\n",
              "  (high, within, high)={ edge_index=[2, 109834] },\n",
              "  (low, to, high)={ edge_index=[2, 126319] }\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "graph"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "478fe98c",
      "metadata": {
        "id": "478fe98c"
      },
      "source": [
        "### Define the test set and corresponding idxs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43fd06ae-eef5-4c0d-9460-a434a9f30751",
      "metadata": {
        "id": "43fd06ae-eef5-4c0d-9460-a434a9f30751"
      },
      "source": [
        "As test set we consider a period of 12 months not used in the training phase. We choose the period 01-12-2015 to 30-11-2016.\n",
        "We start with December and finish with November because to follow the the convenction in climate science to define seasons as:\n",
        "\n",
        "- **DJF**: December, January, February\n",
        "- **MAM**: March, April, May\n",
        "- **JJA**: June, July, August\n",
        "- **SON**: September, October, November"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92217d82",
      "metadata": {
        "id": "92217d82"
      },
      "outputs": [],
      "source": [
        "test_year_start=2015\n",
        "test_month_start=12\n",
        "test_day_start=1\n",
        "test_year_end=2016\n",
        "test_month_end=11\n",
        "test_day_end=30\n",
        "first_year=2001 # This should correspond to the beginning of the data object we want to index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6223062f",
      "metadata": {
        "id": "6223062f"
      },
      "outputs": [],
      "source": [
        "test_start_idx, test_end_idx = date_to_idxs(test_year_start, test_month_start, test_day_start, test_year_end, test_month_end, test_day_end, first_year)\n",
        "if test_start_idx < 24:\n",
        "    test_start_idx = 24\n",
        "test_idxs = torch.tensor([*range(test_start_idx, test_end_idx)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62ecd9d9-a2c9-4d3a-a08a-a85979414f0f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62ecd9d9-a2c9-4d3a-a08a-a85979414f0f",
        "outputId": "47e2cc5d-0c29-48c6-ccc1-b3d71786f062"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8784])"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "test_idxs.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6266bb77-8ee6-418d-8be9-d08f313b4a74",
      "metadata": {
        "id": "6266bb77-8ee6-418d-8be9-d08f313b4a74"
      },
      "source": [
        "Let's also determine the set of idxs for each season."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56d793a6-8083-405e-b9c2-9c231de834f6",
      "metadata": {
        "id": "56d793a6-8083-405e-b9c2-9c231de834f6"
      },
      "outputs": [],
      "source": [
        "# create seasons\n",
        "djf_start = 0 # january-february\n",
        "if test_idxs.shape[0] == 8760:\n",
        "    djf_end = (31*2 + 28) * 24\n",
        "elif test_idxs.shape[0] == 8784:\n",
        "    djf_end = (31*2 + 29) * 24\n",
        "else:\n",
        "    print(\"\\nInvalid number of hours in a year: {y_pred.shape[1]}\")\n",
        "\n",
        "mam_start = djf_end\n",
        "mam_end = mam_start + (31 + 30 + 31) * 24\n",
        "jja_start = mam_end\n",
        "jja_end = jja_start + (31 + 31 + 30) * 24\n",
        "son_start = jja_end\n",
        "son_end = son_start + (30 + 31 + 30) * 24\n",
        "\n",
        "# For convenience, we group the indexis in a single list\n",
        "idxs_seasons = [np.arange(djf_start, djf_end),\n",
        "                np.arange(mam_start, mam_end),\n",
        "                np.arange(jja_start, jja_end),\n",
        "                np.arange(son_start, son_end)]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e6f8fb1",
      "metadata": {
        "id": "5e6f8fb1"
      },
      "source": [
        "### Dataset and Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac71c325",
      "metadata": {
        "id": "ac71c325"
      },
      "outputs": [],
      "source": [
        "# Define the dataset\n",
        "dataset_graph = Dataset_Graph(targets=None, graph=graph)\n",
        "# Define the sampler\n",
        "sampler_graph = Iterable_Graph(dataset_graph=dataset_graph, shuffle=False, idxs_vector=test_idxs)\n",
        "# Define the dataloader\n",
        "dataloader = DataLoader(dataset_graph, batch_size=1, num_workers=0, sampler=sampler_graph, collate_fn=custom_collate_fn_graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32740a9a",
      "metadata": {
        "id": "32740a9a"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d0986bd",
      "metadata": {
        "id": "1d0986bd"
      },
      "outputs": [],
      "source": [
        "model = GNN4CD_model(h_in=4*5, h_hid=4*5, high_in=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3R7RrpCmm3iQ",
        "outputId": "b0d29c8c-8f1e-4eca-df58-ce9b0d9a2717"
      },
      "id": "3R7RrpCmm3iQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GNN4CD_model(\n",
            "  (rnn): Sequential(\n",
            "    (0): GRU(20, 20, num_layers=2, batch_first=True)\n",
            "  )\n",
            "  (dense): Sequential(\n",
            "    (0): Linear(in_features=500, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "  )\n",
            "  (downscaler): Sequential(\n",
            "    (0) - GraphConv((128, 1), 64): x, edge_index -> x\n",
            "  )\n",
            "  (processor): Sequential(\n",
            "    (0) - BatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True): x -> x\n",
            "    (1) - GATv2Conv(64, 64, heads=2): x, edge_index -> x\n",
            "    (2) - BatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True): x -> x\n",
            "    (3) - ReLU(): x -> x\n",
            "    (4) - GATv2Conv(128, 64, heads=2): x, edge_index -> x\n",
            "    (5) - BatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True): x -> x\n",
            "    (6) - ReLU(): x -> x\n",
            "    (7) - GATv2Conv(128, 64, heads=2): x, edge_index -> x\n",
            "    (8) - BatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True): x -> x\n",
            "    (9) - ReLU(): x -> x\n",
            "    (10) - GATv2Conv(128, 64, heads=2): x, edge_index -> x\n",
            "    (11) - BatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True): x -> x\n",
            "    (12) - ReLU(): x -> x\n",
            "    (13) - GATv2Conv(128, 64, heads=1): x, edge_index -> x\n",
            "    (14) - ReLU(): x -> x\n",
            "  )\n",
            "  (predictor): Sequential(\n",
            "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=64, out_features=32, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=32, out_features=1, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "066478c8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "066478c8",
        "outputId": "9ce73d1e-19f7-47db-9ad6-89d1fbc5a2d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "577e2360",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "577e2360",
        "outputId": "3475c6fc-a1bf-4b01-c6b4-28729b8d348f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "# Load the checkpoint\n",
        "checkpoint = torch.load(train_path + f\"checkpoint_{epoch}/pytorch_model.bin\", map_location=torch.device(device))\n",
        "model.load_state_dict(checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0c135ea",
      "metadata": {
        "id": "d0c135ea"
      },
      "outputs": [],
      "source": [
        "model = model.to(device)\n",
        "graph[\"low\"].x = graph[\"low\"].x.to(device)\n",
        "graph[\"high\"].x = graph[\"high\"].x.to(device)\n",
        "graph[\"low\", \"to\", \"high\"].edge_index = graph[\"low\", \"to\", \"high\"].edge_index.to(device)\n",
        "graph[\"high\", \"within\", \"high\"].edge_index = graph[\"high\", \"within\", \"high\"].edge_index.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90aca641",
      "metadata": {
        "id": "90aca641"
      },
      "source": [
        "## Predictions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(dataloader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhUBA-DLevT6",
        "outputId": "8667c131-9552-4495-b59e-d94e1d9ee8da"
      },
      "id": "NhUBA-DLevT6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8784\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, dataloader):\n",
        "    model.eval()\n",
        "    step = 0\n",
        "\n",
        "    y_pred_list = []\n",
        "    times_list = []\n",
        "    steps = len(dataloader)\n",
        "\n",
        "    with torch.no_grad():\n",
        "       for i, graph in enumerate(dataloader):\n",
        "\n",
        "            t = graph.t\n",
        "            times_list.append(t)\n",
        "\n",
        "            # Regressor\n",
        "            y_pred = model(graph)\n",
        "            y_pred_list.append(y_pred)\n",
        "\n",
        "            percentage = i / steps * 100\n",
        "            if percentage % 10 == 0:\n",
        "                print(f\"{percentage:.0f}% done\")\n",
        "                step += 1\n",
        "       print(\"100% done\")\n",
        "\n",
        "    y_pred_list = torch.cat(y_pred_list, dim=-1)\n",
        "    times_list = torch.cat(times_list, dim=-1)\n",
        "    return y_pred_list, times_list\n",
        "\n"
      ],
      "metadata": {
        "id": "sf4UGVFXnQxP"
      },
      "id": "sf4UGVFXnQxP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0de8e6c6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0de8e6c6",
        "outputId": "0eaa1c57-231e-49ef-8c5b-0716f4385b53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0% done\n",
            "50% done\n",
            "100% done\n",
            "150% done\n",
            "200% done\n",
            "250% done\n",
            "300% done\n",
            "350% done\n",
            "400% done\n",
            "450% done\n",
            "500% done\n",
            "550% done\n",
            "600% done\n",
            "650% done\n",
            "700% done\n",
            "750% done\n",
            "800% done\n",
            "850% done\n",
            "900% done\n",
            "950% done\n",
            "1000% done\n",
            "1050% done\n",
            "1100% done\n",
            "1150% done\n",
            "1200% done\n",
            "1250% done\n",
            "1300% done\n",
            "1350% done\n",
            "1400% done\n",
            "1450% done\n",
            "1500% done\n",
            "1550% done\n",
            "1600% done\n",
            "1650% done\n",
            "1700% done\n",
            "1750% done\n",
            "1800% done\n",
            "1850% done\n",
            "1900% done\n",
            "1950% done\n",
            "2000% done\n",
            "2050% done\n",
            "2100% done\n",
            "2150% done\n",
            "2200% done\n",
            "2250% done\n",
            "2300% done\n",
            "2350% done\n",
            "2400% done\n",
            "2450% done\n",
            "2500% done\n",
            "2550% done\n",
            "2600% done\n",
            "2650% done\n",
            "2700% done\n",
            "2750% done\n",
            "2800% done\n",
            "2850% done\n",
            "2900% done\n",
            "2950% done\n",
            "3000% done\n",
            "3050% done\n",
            "3100% done\n",
            "3150% done\n",
            "3200% done\n",
            "3250% done\n",
            "3300% done\n",
            "3350% done\n",
            "3400% done\n",
            "3450% done\n",
            "3500% done\n",
            "3550% done\n",
            "3600% done\n",
            "3650% done\n",
            "3700% done\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-148105692.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-1715271431.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, dataloader)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;31m# Regressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0my_pred_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-14828414.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data, inference)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mencod_low2high\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownscaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencod_rnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'high'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"low\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"to\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"high\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mencod_high\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencod_low2high\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'high'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'within'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'high'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mx_high\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencod_high\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minference\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1699\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1700\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1701\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1702\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "predictions, times = test(model, dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "233d9616-6cae-4b20-b348-4741da8f81a3",
      "metadata": {
        "id": "233d9616-6cae-4b20-b348-4741da8f81a3"
      },
      "outputs": [],
      "source": [
        "print(np.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b6ae496-e232-4c98-9c34-ba4b9c13f3ea",
      "metadata": {
        "id": "7b6ae496-e232-4c98-9c34-ba4b9c13f3ea"
      },
      "source": [
        "The target data used to train the model were scaled to [0,1] interval, thus we need to rescale back the predictions to the original range."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbb36abe-6c78-4361-bb4b-dc4c03236745",
      "metadata": {
        "id": "fbb36abe-6c78-4361-bb4b-dc4c03236745"
      },
      "outputs": [],
      "source": [
        "# Convert to numpy array for visualizations\n",
        "predictions = predictions.cpu().numpy()\n",
        "\n",
        "# Rescale back to the original range\n",
        "min_val = 250\n",
        "max_val= 350\n",
        "predictions = predictions * (max_val - min_val) + min_val\n",
        "\n",
        "# Convert to Celsius\n",
        "predictions = predictions - 273.15\n",
        "\n",
        "target_test = target[:, test_idxs]\n",
        "target_test = target_test - 273.15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2851ce52-bcfd-4ea4-942b-8c3ee02c8724",
      "metadata": {
        "id": "2851ce52-bcfd-4ea4-942b-8c3ee02c8724"
      },
      "outputs": [],
      "source": [
        "target_test = target_test.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09a5ad81-0fcc-4180-8d0e-61c81622687f",
      "metadata": {
        "id": "09a5ad81-0fcc-4180-8d0e-61c81622687f"
      },
      "outputs": [],
      "source": [
        "predictions.min(), predictions.max(), target_test.min(), target_test.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3ff4393-d549-4eac-9bf3-5bb4e7101337",
      "metadata": {
        "id": "c3ff4393-d549-4eac-9bf3-5bb4e7101337"
      },
      "outputs": [],
      "source": [
        "shapefile_path = os.path.join(DATA_PATH+\"ne_10m_admin_0_countries\", \"ne_10m_admin_0_countries.shp\")\n",
        "\n",
        "# Load and filter for Italy\n",
        "world = gpd.read_file(shapefile_path)\n",
        "italy = world[world['NAME'] == 'Italy']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8c8ba3e-8042-412a-88f1-a33578759f97",
      "metadata": {
        "id": "a8c8ba3e-8042-412a-88f1-a33578759f97"
      },
      "outputs": [],
      "source": [
        "coolwarm_30 = discrete_cmap(30, 'coolwarm')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56b2bf46-6288-4e13-b5df-c47f51a109aa",
      "metadata": {
        "id": "56b2bf46-6288-4e13-b5df-c47f51a109aa"
      },
      "source": [
        "### Spatial map of average temperature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36892178",
      "metadata": {
        "id": "36892178"
      },
      "outputs": [],
      "source": [
        "# Plot\n",
        "xsize = 16\n",
        "ysize = 12\n",
        "xlim = [6.55, 14.00]\n",
        "ylim = [43.70, 47.15]\n",
        "\n",
        "matplotlib.rcParams.update({'font.size': 24})\n",
        "\n",
        "predictions_mean = np.nanmean(predictions, axis=1)\n",
        "target_mean = np.nanmean(target_test, axis=1)\n",
        "\n",
        "vmin=min(predictions_mean.min(), target_mean.min())\n",
        "vmax=max(predictions_mean.max(), target_mean.max())\n",
        "\n",
        "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(xsize*2, ysize))\n",
        "\n",
        "ax[0].scatter(graph[\"high\"].lon, graph[\"high\"].lat, c=predictions_mean, marker='s', s=30, cmap=coolwarm_30, vmin=vmin, vmax=vmax)\n",
        "italy.boundary.plot(ax=ax[0], edgecolor='black', linewidth=1)\n",
        "ax[0].set_title(\"predictions\")\n",
        "ax[0].set_xlim(xlim)\n",
        "ax[0].set_ylim(ylim)\n",
        "im = ax[1].scatter(graph[\"high\"].lon, graph[\"high\"].lat, c=target_mean, marker='s', s=30, cmap=coolwarm_30, vmin=vmin, vmax=vmax)\n",
        "italy.boundary.plot(ax=ax[1], edgecolor='black', linewidth=1)\n",
        "ax[1].set_title(\"ground truth\")\n",
        "ax[1].set_xlim(xlim)\n",
        "ax[1].set_ylim(ylim)\n",
        "cbar_ax = fig.add_axes([0.93, 0.16, 0.02, 0.6]) # (left, bottom, width, height) in fractions of figure width and height\n",
        "cbar = fig.colorbar(im, cax=cbar_ax, aspect=25)\n",
        "cbar.ax.set_title(\"[°C]\", rotation=0, y=1.05)\n",
        "plt.suptitle(\"Average t2m (01-12-2015 to 30-11-2016)\", y=0.87)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12861c97-24d8-45bf-8aea-b64d6698aee5",
      "metadata": {
        "id": "12861c97-24d8-45bf-8aea-b64d6698aee5"
      },
      "source": [
        "### RMSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb72eff1-1035-4056-9a1e-a45d0c2334a1",
      "metadata": {
        "id": "bb72eff1-1035-4056-9a1e-a45d0c2334a1"
      },
      "outputs": [],
      "source": [
        "YlGnBu_30 = discrete_cmap(30, 'YlGnBu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "274781cd-ccb8-4e51-a6a3-22c41e8e1b1f",
      "metadata": {
        "id": "274781cd-ccb8-4e51-a6a3-22c41e8e1b1f"
      },
      "outputs": [],
      "source": [
        "# Plot\n",
        "xsize = 16\n",
        "ysize = 12\n",
        "xlim = [6.55, 14.00]\n",
        "ylim = [43.70, 47.15]\n",
        "\n",
        "matplotlib.rcParams.update({'font.size': 22})\n",
        "\n",
        "predictions_mean = np.nanmean(predictions, axis=1)\n",
        "target_mean = np.nanmean(target_test, axis=1)\n",
        "\n",
        "t2m_rmse = rmse(predictions, target_test)\n",
        "\n",
        "vmin=0\n",
        "vmax=t2m_rmse.max() + 1\n",
        "\n",
        "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(xsize, ysize))\n",
        "\n",
        "im = ax.scatter(graph[\"high\"].lon, graph[\"high\"].lat, c=t2m_rmse, marker='s', s=16, cmap=YlGnBu_30, vmin=vmin, vmax=vmax)\n",
        "italy.boundary.plot(ax=ax, edgecolor='black', linewidth=1)\n",
        "ax.set_xlim(xlim)\n",
        "ax.set_ylim(ylim)\n",
        "\n",
        "cbar_ax = fig.add_axes([0.95, 0.16, 0.025, 0.65]) # (left, bottom, width, height) in fractions of figure width and height\n",
        "cbar = fig.colorbar(im, cax=cbar_ax, aspect=25)\n",
        "cbar.ax.set_title(\"[°C]\", rotation=0, y=1.05)\n",
        "plt.suptitle(\"RMSE t2m (01-12-2015 to 30-11-2016)\", y=0.87)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7322a94-6209-4c1f-b371-245f520cf4b6",
      "metadata": {
        "id": "a7322a94-6209-4c1f-b371-245f520cf4b6"
      },
      "source": [
        "### PDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e67dfbb-25f9-47aa-9833-cc15df242c8b",
      "metadata": {
        "id": "6e67dfbb-25f9-47aa-9833-cc15df242c8b"
      },
      "outputs": [],
      "source": [
        "range_bins=[-20,35,0.5]\n",
        "plot_pdf(predictions, target_test, range_bins, ylim=[0,0.03], xlabel=\"t2m [°C]\",fontsize=10, suptitle=\"PDF t2m (01-12-2015 to 30-11-2016)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31910fe7-f758-40dd-acbc-843ebeb333f7",
      "metadata": {
        "id": "31910fe7-f758-40dd-acbc-843ebeb333f7"
      },
      "source": [
        "## Seasonal results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cc89b68-7de8-490a-ae39-74ec2e3ed60b",
      "metadata": {
        "id": "1cc89b68-7de8-490a-ae39-74ec2e3ed60b"
      },
      "source": [
        "### Diurnal cycles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e213f6fb-bc31-4167-b0bb-89ba36cd649a",
      "metadata": {
        "id": "e213f6fb-bc31-4167-b0bb-89ba36cd649a"
      },
      "outputs": [],
      "source": [
        "plot_diurnal_cycles(predictions, target_test, idxs_seasons=idxs_seasons, ylablel=\"[°C]\", figsize=(8*4,8), fontsize=26, ylim=[0,25],\n",
        "                   suptitle=\"Diurnal Cycles t2m (01-12-2015 to 30-11-2016)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d6cae93-2339-4666-8936-611dea189a24",
      "metadata": {
        "id": "2d6cae93-2339-4666-8936-611dea189a24"
      },
      "source": [
        "### RMSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "567f6861-c6ec-4c82-9e1d-32827569a574",
      "metadata": {
        "id": "567f6861-c6ec-4c82-9e1d-32827569a574"
      },
      "outputs": [],
      "source": [
        "YlGnBu_30 = discrete_cmap(30, 'YlGnBu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38ddb258-001a-49a0-b6b8-383649071066",
      "metadata": {
        "id": "38ddb258-001a-49a0-b6b8-383649071066"
      },
      "outputs": [],
      "source": [
        "# Plot\n",
        "xsize = 16\n",
        "ysize = 12\n",
        "xlim = [6.55, 14.00]\n",
        "ylim = [43.70, 47.15]\n",
        "\n",
        "matplotlib.rcParams.update({'font.size': 24})\n",
        "\n",
        "predictions_mean = np.nanmean(predictions, axis=1)\n",
        "target_mean = np.nanmean(target_test, axis=1)\n",
        "\n",
        "t2m_rmse = rmse(predictions, target_test)\n",
        "\n",
        "vmin=0\n",
        "vmax=t2m_rmse.max() + 1\n",
        "\n",
        "fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(xsize*2, ysize*2))\n",
        "text_list = ['DJF', 'MAM', 'JJA', 'SON']\n",
        "\n",
        "for s in range(4):\n",
        "    axi = ax[s//2, s%2]\n",
        "    idxs_s = idxs_seasons[s]\n",
        "\n",
        "    im = axi.scatter(graph[\"high\"].lon, graph[\"high\"].lat, c=rmse(predictions[:,idxs_s], target_test[:,idxs_s]),\n",
        "                     marker='s', s=30, cmap=YlGnBu_30, vmin=vmin, vmax=vmax)\n",
        "    italy.boundary.plot(ax=axi, edgecolor='black', linewidth=1)\n",
        "    axi.set_title(text_list[s])\n",
        "    axi.set_xlim(xlim)\n",
        "    axi.set_ylim(ylim)\n",
        "\n",
        "cbar_ax = fig.add_axes([0.95, 0.16, 0.025, 0.65]) # (left, bottom, width, height) in fractions of figure width and height\n",
        "cbar = fig.colorbar(im, cax=cbar_ax, aspect=25)\n",
        "cbar.ax.set_title(\"[°C]\", rotation=0, y=1.05)\n",
        "fig.suptitle(\"Seasonal RMSE tm2 (01-12-2015 to 30-11-2016)\", y=0.9)\n",
        "plt.subplots_adjust(hspace=0)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}